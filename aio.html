<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>HPC User: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="site.webmanifest">
<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      HPC User
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            HPC User
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  HPC User
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="introduction.html">1. Introduction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="profiling-code.html">2. Profiling Code for Performance</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="performance-concepts.html">3. Performance Concepts</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="parallel-concepts.html">4. Parallel Computing Concepts</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="multi-threaded.html">5. Multi-Threaded Programs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="message-passing.html">6. Message-Passing Programs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="language-survey.html">7. Language Survey</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="c-cpp.html">8. C and C++ Languages</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="fortran.html">9. The Fortran Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="python.html">10. The Python Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush12">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading12">
        <a href="r.html">11. The R Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush13">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading13">
        <a href="matlab.html">12. The Matlab Language</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush14">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading14">
        <a href="array-jobs.html">13. Array Jobs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush15">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading15">
        <a href="gpus.html">14. Accelerating Scientific Computing with GPUs</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush16">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading16">
        <a href="high-throughput-computing.html">15. High-Throughput Computing</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush17">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading17">
        <a href="hpc-resources.html">16. HPC Resources</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-introduction"><p>Content from <a href="introduction.html">Introduction</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What should I expect to learn from the HPC User module?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Set the basis for learning about High-Performance Computing in
Science.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<hr class="half-width">
<p>In doing computational science it is very common to start a project
by writing code on a personal computer. Often as the project proceeds we
find that we need more computer resources to complete the science
project. This may come in the form of needing more processing power to
complete the research in a reasonable time. It may also mean needing
more memory to be able to run larger calculations. Or it may just mean
needing to do a very large number of smaller jobs that would overwhelm a
single computer system.</p>
<p>In these cases where we need to seek out more computational
resources, we also need to start understanding the performance aspects
of our code. More power is not always the answer, sometimes writing more
efficient code can get the job done equally as well.</p>
<p>This HPC User lesson is aimed at scientists who need to use computers
to do calculations, and not at computer scientists or computer engineers
who need to be experts at programming in a High-Performance Computing
environment. This lesson will be aimed at giving an overview of
performance concepts to provide a general understanding of how to
operate in an HPC environment.</p>
</section><section><h2 class="section-heading" id="organization">Organization<a class="anchor" aria-label="anchor" href="#organization"></a>
<a class="anchor" aria-label="anchor" href="#organization"></a>
</h2>
<hr class="half-width">
<p>The first few chapters concentrate on discussing performance issues
at the conceptual level with practical examples. <strong>These examples
are currently given in Python but it is intended to eventually have the
user and instructor choose the language that the examples display in to
make it more appropriate to teach this to groups primarily interested in
R, C/C++, Fortran, or Matlab too</strong>. As the lesson proceeds these
same concepts will be used in different ways and with examples in
different computer languages to help drill them in.</p>
<p>The middle third of the lesson is a language survey. Even though most
scientists may work primarily in a single language, it is important to
understand the strengths and weaknesses of alternative languages as well
as their own favorite.</p>
<p>The last sections provide overviews of some more advanced topics like
working with GPUs to accelerate scientific codes. It may be that some of
this will be skipped by your instructor due to time limitations but it
is good to have these available for reference purposes.</p>
<p>There are hands-on exercises throughout the lesson where you will be
asked to apply some of what you have learned. There are also optional
homework assignments available for those who want to challenge
themselves outside of the workshop.</p>
<p>Most sections also have website links at the end which provide a
means to seek out more information.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>The HPC User lesson will help to understand basic concepts affecting
performance in programming.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-profiling-code"><p>Content from <a href="profiling-code.html">Profiling Code for Performance</a></p>
<hr>
<p>Last updated on 2024-08-20 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/profiling-code.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How to measure performance?</li>
<li>How to measure memory usage?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn the different methods available to measure time and memory
usage externally and from within a program.</li>
<li>Understand what parts of a program are important to time.</li>
<li>Learn how to do a scaling study for multi-core and multi-node
jobs.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>When we talk about the performance of a program, we are always
interested in how much time it takes to run, but in some cases we also
need to know how much memory the program uses if we are pushing the
limits of our computer. Even more than that, we often need to know how
much time each part of the code takes so that we know where to
concentrate our efforts as we try to improve the overall performance of
the program. So we need to be able to time the entire run, and also
internally each part of the code. For parallel codes, we also need to
know how efficiently they scale as we increase the number of cores or
compute nodes in order to determine what resources to request.</p>
<section><h2 class="section-heading" id="timing-a-program-externally">Timing a Program Externally<a class="anchor" aria-label="anchor" href="#timing-a-program-externally"></a>
<a class="anchor" aria-label="anchor" href="#timing-a-program-externally"></a>
</h2>
<hr class="half-width">
<p>Linux has a <strong>time</strong> function that can proceed any
command, so this can be used to time the entire job externally even if
we don’t have access to the source code. This can be used to time a
short test run in order to estimate the runtime needed for the complete
job. When we get to talking about parallel computing, or using multiple
compute cores to run a single job, the <strong>time</strong> function
will prove useful for getting the execution time for a job as it depends
on the number of cores. For example, it is common to test the same job
on 1, 4, 8, 16, and 32 cores to see how it scales with more cores to
determine what number of cores is most efficient to use.</p>
<p>Let’s start with a few simple examples of using the
<strong>time</strong> function at the command prompt. Try timing the
<strong>pwd</strong> command which prints the current working
directory.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="bu">time</span> pwd</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>/Users/daveturner

real	0m0.000s
user	0m0.000s
sys	0m0.000s</code></pre>
</div>
<p>The first thing you see is the output of the <strong>pwd</strong>
command, which in this case is the directory
<strong>/Users/daveturner</strong> on my Mac. Then the
<strong>time</strong> function prints its output, always as real time,
which is what we want, then user and system time which we can ignore.
This shows that the <strong>pwd</strong> command is faster than the
clock can measure. This is important to note that the
<strong>time</strong> command isn’t accurate to less than 1 millisecond,
so in general we should always make sure we are measuring execution
times that are greater than a second in general.</p>
<p>Below is another example where this time we are timing the
<strong>ls</strong> function which will list the files in the current
directory.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="bu">time</span> ls</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>file1 file2 file3

real	0m0.110s
user	0m0.006s
sys	0m0.027s</code></pre>
</div>
<p>When I do this on my Mac, I get a real time of just 0.006 seconds
because it’s really fast to access the local hard disk. The test above
is from a very large cluster computer that has a parallel file server
with 1 Petabyte of storage (1 Petabyte is 1000 Terabytes, and each
Terabyte is 1000 Gigabytes). The performance for accessing large files
on a parallel file server is very good, but it does take longer to do
small tasks like get the contents of the current directory. How does
this compare to the system you are on? On large HPC (High-Performance
Computing) systems like this cluster, the speed also depends on what
file system you are testing. You can usually access the local disk at
/tmp, but your home directory may be on another file system, and often
there is fast scratch space that is very high performance but only used
for programs when they are running.</p>
<p>Below we are going to use the <strong>sleep</strong> command to time
an interval of 5 seconds just to simulate what we might see in a real
job. In this case, even though the sleep function was supposed to go 5
seconds, there was some overhead or inaccuracy in the timnig routine or
the length of the sleep. This is one thing that you always need to be
aware of when measuring performance. If you are measuring short things,
you may want to measure multiple times and take an average.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="bu">time</span> sleep 5</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>real	0m5.052s
user	0m0.001s
sys	0m0.003s</code></pre>
</div>
<p>In addition to worrying about the clock accuracy, you also need to
worry about interferrence from other jobs that may be running on the
same compute node you are on. The best way to time a real job is to test
it out on a completely isolated computer. If you are on an HPC system
with a batch queue, you can always request an entire compute node and
then just use part of the node you requested, even a single compute
core. If this is not possible, then try to get the job as isolated as
you can. Submitting a single-core request to a job queue is one example
of this, where you at least are sure that your job is the only one on
the cores that you requested. Your job will still be sharing the memory
bus and L3 cache with other jobs. Jobs usually don’t effect each other
much from this, but they can. If your job is using the network to
communicate with other compute nodes, that might also be shared with
other jobs running on the same node. The single largest factor to be
aware of is that other jobs using the same file server as you are can
definitely affect the peroformance of your job if your code is doing
lots of IO (Input and Output). On HPC systems, this can be true even if
the other jobs are not on the same compute node as your job. If you want
to isolate your job from others in this case, you will need to do your
IO to the local disk (usually /tmp).</p>
</section><section><h2 class="section-heading" id="timing-internal-parts-of-a-program">Timing Internal Parts of a Program<a class="anchor" aria-label="anchor" href="#timing-internal-parts-of-a-program"></a>
<a class="anchor" aria-label="anchor" href="#timing-internal-parts-of-a-program"></a>
</h2>
<hr class="half-width">
<p>Every computer language has multiple <strong>clock()</strong>
functions that can be used to time sections of the code. The syntax is
different in each language, but they all work about the same, and there
is always a very high precision function that is accurate down to
somewhere in the nanosecond range, though I typically don’t trust these
for measuring less than a microsecond interval. Each of these clock
functions returns the current time, so to measure the time in an
interval you need to store the start time, do some calculations or IO,
then get the end time and subtract the two to get the time used for that
part of the code.</p>
<p>In Python since version 3.3, the best timer is in the
<strong>time</strong> package. To use it, you must start by importing
the package. Below is an example of using the clock function to measure
the time it takes to do a loop, then measure the time it takes to dump
an array out to a file.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" aria-labelledby="nav-tab-1-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># timing_example.py - Example code showing how to put timing around an IO loop.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>array <span class="op">=</span> [ <span class="bu">float</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="bu">sum</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>   <span class="bu">sum</span> <span class="op">+=</span> array[i]</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>t_loop <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The loop took "</span>, t_loop, <span class="st">" seconds"</span>)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>fd <span class="op">=</span> <span class="bu">open</span>( <span class="st">"array.out"</span>, <span class="st">"w"</span>)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>   fd.write( <span class="bu">str</span>(array[i]) <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span> )</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>fd.close()</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>t_output <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The output took "</span>, t_output, <span class="st">" seconds"</span>)</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" aria-labelledby="nav-tab-1-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" aria-labelledby="nav-tab-1-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" aria-labelledby="nav-tab-1-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" aria-labelledby="nav-tab-1-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>Try running the <strong>timing_example.py</strong> code yourself. It
is one of the codes you should have downloaded and unzipped in your HPC
system, and should be in the <strong>code</strong> directory. You should
also have the Python environment set up and have done the <strong>pip
install time</strong>. When I run this, I see that the loop takes about
30 microseconds on my computer and the output file takes 10
milliseconds. Since both of these are above the nanosecond range, we can
be confident that the timing routine is accurately measuring each.</p>
<p>Let’s see what we can learn by playing around with it some more. When
I run this with <strong>time python timing_example.py</strong>, I see a
real time of 100 milliseconds even though the loop time and output time
combined are only about a half millisecond. The initialization time is
not measured but shouldn’t be more than the loop time. What all this
means is that there is some startup time for getting the python program
running and importing the <strong>time</strong> package, but we may also
be seeing the lack of accuracy of the external <strong>time</strong>
function when it comes to measuring things down in the millisecond
range.</p>
<p>Now lets change the <strong>timing_example.py</strong> program
itself. Sometimes we need to time a part of something that is in a
larger loop, so we need to sum the times together. Try changing the
timing so that it is inside the summation loop instead of outside it to
see what happens. You can do this by uncommenting the timing and
printing functions in the <strong>timing_example.py</strong> file.</p>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" aria-labelledby="nav-tab-2-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>array <span class="op">=</span> [ <span class="bu">float</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="bu">sum</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>t_sum <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>   t0 <span class="op">=</span> time.perf_counter()</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>   <span class="bu">sum</span> <span class="op">+=</span> array[i]</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>   t_sum <span class="op">+=</span> time.perf_counter() <span class="op">-</span> t0</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>t_loop <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The sum took "</span>, t_sum, <span class="st">" seconds"</span>)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The loop took "</span>, t_loop, <span class="st">" seconds"</span>)</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>fd <span class="op">=</span> <span class="bu">open</span>( <span class="st">"array.out"</span>, <span class="st">"w"</span>)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>   fd.write( <span class="bu">str</span>(array[i]) <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span> )</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>fd.close()</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>t_output <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The output took "</span>, t_output, <span class="st">" seconds"</span>)</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" aria-labelledby="nav-tab-2-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" aria-labelledby="nav-tab-2-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" aria-labelledby="nav-tab-2-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" aria-labelledby="nav-tab-2-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>In my computer, the <strong>t_sum</strong> time is only a bit larger
than the <strong>t_loop</strong> time from before, but remember that
this doesn’t count the loop overhead. If we look at the
<strong>t_loop</strong> time instead, in my computer it is more than
double what it was before. When the clock routine is measuring very
small intervals each time, it can be intrusive in that it distorts the
measurement by increasing the runtime of the entire code. It isn’t
surprising that this is intrusive since we are measuring the time it
takes to retrieve a single array element and do one addition. The code
is doing a subtraction and addition itself to calculate the time
interval, so it is probably more surprising that doing the timing in
this way is not more intrusive.</p>
</section><section><h2 class="section-heading" id="what-to-time">What to Time<a class="anchor" aria-label="anchor" href="#what-to-time"></a>
<a class="anchor" aria-label="anchor" href="#what-to-time"></a>
</h2>
<hr class="half-width">
<p>The goal is to fully profile your code so that you understand where
all the time is being spent. This means timnig each computational
section where time is being spent, usually the loops for example. While
simple print statements may not be important contributers to the overall
runtime of a code, any large input or output from files may be. When we
start talking about parallel programs that use multiple cores or even
multiple compute nodes it will become important to measure the time
taken in communicating data to other cores and other nodes. Once you
have a complete profile of where time is being spent, then you can
understand where to start in trying to optimize your program to make it
run faster.</p>
</section><section><h2 class="section-heading" id="measuring-parallel-job-scaling">Measuring Parallel Job Scaling<a class="anchor" aria-label="anchor" href="#measuring-parallel-job-scaling"></a>
<a class="anchor" aria-label="anchor" href="#measuring-parallel-job-scaling"></a>
</h2>
<hr class="half-width">
<p>When we get to talking about multi-processor jobs it will be very
important to understand how efficiently a job scales as we use more
processing cores. For this we will do what is called a scaling study
where we measure the performance of a typical job using different number
of processing cores. We may for example run on 1 core, then 4, 8, 16,
and 32 cores to see how efficiently the job scales as we apply more
processing power. This is done so that we can understand how many cores
we can efficiently apply to that job. If we get a 7 times speedup on 8
cores compared to 1, that less than ideal but still very good. If we
then see a 9 times speedup using 16 cores, then we’d probably want to
stick with using just 8 cores on that particular job. Do keep in mind
that scaling is very dependent on the problem size. Larger problems will
typically scale better to more cores, while smaller problems may be
limited to only a few cores. The goal is to determine how many cores we
can use with reasonable efficiency. The same kind of scaling study can
also be used for multi-node jobs, where we would test the performance on
1 node, 2, 4, and 8 nodes for example.</p>
<p>Problem size is one factor that can affect the scaling efficiency.
For multi-node jobs, choosing the fastest networking options, and
ensuring that all compute nodes are on the same network switch can both
increase the scaling efficiency.</p>
</section><section><h2 class="section-heading" id="tracking-memory-usage">Tracking Memory Usage<a class="anchor" aria-label="anchor" href="#tracking-memory-usage"></a>
<a class="anchor" aria-label="anchor" href="#tracking-memory-usage"></a>
</h2>
<hr class="half-width">
<p>When we think about high peformance, we mostly think about running
jobs faster. For some programs, the memory usage may be the factor
limiting what types of science we can do. At the very least, we need to
know what memory to request when submitting jobs to a batch
scheduler.</p>
<p>For simple jobs, like the matrix multiplication code in the next
section, we can calculate the exact memory requirements. If we are going
to multiply two matrices of size NxN and put the results in a third,
then each matrix takes NxN x 8 Bytes if the elements are 64-bit floats,
so the total memory required would be 3 x NxN * 8 Bytes.</p>
<p>For more complicated programs, often the best approach is to do a
short test run to measure the memory use before submitting the full job.
This is especially true if you are submitting lots of similar jobs. If
your job goes over the requested memory, it is most often killed, so you
want to over estimate the request somewhat, but if you request too much
it can take a lot longer to get your job scheduled and result in
inefficient use of the resources as you will be locking up memory that
you are not using.</p>
<p>Measuring the memory usage is more difficult than it should be on
most systems, and it depends on what tools you have available. If you
are on an HPC system with a batch scheduler like Slurm, you can use the
<strong>sstat</strong> command to find the current memory usage for a
running job and <strong>seff</strong> to find the maximum memory used
for a completed job, using the job ID number in both cases to choose the
job you are interested in.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">seff</span> 5072064</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Job ID: 5072064
Cluster: beocat
User/Group: daveturner/daveturner_users
State: FAILED (exit code 16)
Cores: 1
CPU Utilized: 00:01:07
CPU Efficiency: 97.10% of 00:01:09 core-walltime
Job Wall-clock time: 00:01:09
Memory Utilized: 2.26 GB
Memory Efficiency: 11.31% of 20.00 GB</code></pre>
</div>
<p>The matrix multiplication job above used 10,000x10,000 matrices and
took 1 minute 9 seconds. We see that in this case it used 2.26 GB of
memory. One thing to keep in mind is that 1 GB can be calculated in
different ways. In this case, 1 kB is 1024 Bytes, 1 MB is 1024 x 1024
Bytes, and 1 GB is 1024 x 1024 x 1024 Bytes. So 3 matrices are 3 x NxN x
8 / (1024x1024x1024) GB = 2.235 GB, rounded up to 2.26 GB. In general,
if you estimate 1 GB as 10^9 Bytes that works fine.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="ex">sstat</span> <span class="at">--format</span><span class="op">=</span>MaxRSS 5072069</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>MaxRSS
----------
  2289.50M</code></pre>
</div>
<p>For a running job you can use the <strong>sstat</strong> command with
the job ID number. The <strong>sstat</strong> command will dump a lot of
information out, so using the <strong>–format=MaxRSS</strong> parameter
provides just the real memory that we want. In this case, it is again
2.29 GB.</p>
<p>Different HPC systems may have batch queue systems other than Slurm,
but all will have similar methods of getting the memory usage for
running and completed jobs. If you are not running a job through a batch
system, you can use the <strong>htop</strong> command to find your
process and look at the <strong>Res</strong> or resident memory. This
works best for single-core jobs as multi-core jobs may show memory usage
for each thread.</p>
<p><strong>Ganglia</strong> is another option providing a web-based
interface to look at memory usage over time. If you have access to
Ganglia on your HPC system, it provides a node view only rather than a
job view, so it is only really useful if your job is the only one
running on a given compute node. However, being able to see the memory
use over time can be very helpful.</p>
<p>We will practice these approaches more in the upcoming modules.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>The <strong>time</strong> function can always be used externally to
measure performance but has limitted accuracy of around 1
millisecond.</li>
<li>Internally there are precise clock routines that can be used to
measure the performance of each part of a code. These are different for
each programming language, but the use is always the same.</li>
<li>Scaling studies can help determine how many cores or nodes we can
efficiently use for a parallel job of a given problem size.</li>
<li>Measuring memory use can be done from outside a program, but you may
also be able to calculate total memory for simple programs.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-performance-concepts"><p>Content from <a href="performance-concepts.html">Performance Concepts</a></p>
<hr>
<p>Last updated on 2024-08-16 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/performance-concepts.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What does performance mean in programming?</li>
<li>How do I take advantage of optimized libraries?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand that what actually goes on in the computer may be much
more complex than what the user tells the computer to do.</li>
<li>Have a basic understanding of some of the performance issues to be
aware of.</li>
<li>Learn that you don’t have to be an expert programmer to take
advantage of advanced performance techniques, you just need to be aware
of how to use libraries optimized by experts.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="conceptual-view">Conceptual View<a class="anchor" aria-label="anchor" href="#conceptual-view"></a>
<a class="anchor" aria-label="anchor" href="#conceptual-view"></a>
</h2>
<hr class="half-width">
<p>When we write a program for a computer, we view the operation from a
more conceptual level. The picture below is for a simple dot product
between two vectors <strong>X</strong> and <strong>Y</strong>, where the
dot product <strong>D</strong> is the sum of the elements of each vector
multiplied together. Notice first that the indexing for arrays in Python
starts at 0 and goes to N-1. This varies between languages, with C/C++
also starting at 0, while R, Matlab, and Fortran start arrays at 1 and
go to N.</p>
<p>When we think of a computer running a program to do this calculation,
we view it as starting with the variable <strong>D</strong> being pulled
from main memory into the processor where this sum is zeroed out. We
then start by pulling <strong>X<sub>0</sub></strong> up into the
processor, then <strong>Y<sub>0</sub></strong>, multiplying them
together and summing them into <strong>D</strong>. We loop through all
elements of the vectors, each time pulling the <strong>X</strong> and
<strong>Y</strong> element into memory, multiplying them together and
summing them into <strong>D</strong>. Then at the end, we push
<strong>D</strong> back down into main memory where the program prints
the result out to the screen for us.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" aria-labelledby="nav-tab-1-Python" role="tabpanel">
<figure><img src="fig/dot_prod_fig.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" aria-labelledby="nav-tab-1-R" role="tabpanel">
<p>Need fig/dot_prod_fig-1-N.jpg</p>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" aria-labelledby="nav-tab-1-C" role="tabpanel">
<figure><img src="fig/dot_prod_fig.jpg" alt="Dot product formula" class="figure mx-auto d-block"><div class="figcaption">Dot product between vectors X and Y</div>
</figure>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" aria-labelledby="nav-tab-1-Fortran" role="tabpanel">
<p>Need fig/dot_prod_fig-1-N.jpg</p>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" aria-labelledby="nav-tab-1-Matlab" role="tabpanel">
<p>Need fig/dot_prod_fig-1-N.jpg</p>
</div>
</div>
</div>
<p>This conceptual view of what the computer is doing is all we really
need to be aware of when we are starting to writing programs. But when
those programs start taking too long to run on a desktop computer then
we need to understand what the computer is doing in more depth so we can
make sure that the code is running optimally. Computers are internally
quite complex, so fully understanding how code can be written in
different ways to streamline the processing can be very challenging.
Fortunately, not everyone needs to be able to write optimal low-level
code. For most of us, we just need to understand what programming
techniques in each language may cause performance problems, and
understand how to take advantage of optimization libraries that experts
have written for us.</p>
</section><section><h2 class="section-heading" id="the-computers-view">The Computer’s View<a class="anchor" aria-label="anchor" href="#the-computers-view"></a>
<a class="anchor" aria-label="anchor" href="#the-computers-view"></a>
</h2>
<hr class="half-width">
<p>Let’s walk through the same dot product example again, but this time
looking at it from the point of view of the computer rather than our
conceptual view. The first thing to understand is that when you pull a
variable up from main memory into the registers in a processor, what
goes on behind the scene is very complicated, but fortunately for us
also totally automated. Variables don’t get pulled up individually but
as part of a 64-byte cache line. The variables in this cache line get
promoted through several layers of increasingly fast memory known as
cache layers, with a copy of the entire cache line being left behind in
each layer. In this way, the most frequently used data will be more
likely to be in one of the cache layers where it can be accessed more
quickly. In the case of our dot product, that means loading the first
element <strong>X<sub>1</sub></strong> may take 10-33 ns while the next
7 only take 0.3-1 ns since they are already in L1 cache.</p>
<figure><img src="fig/Memory_Hierarchy.jpg" alt="Diagram of the memory hierarchy in a typical computer" class="figure mx-auto d-block"><div class="figcaption">Memory Hierarchy in a Computer</div>
</figure><p>How does this knowledge help us? Performance is more about getting
data to the processor since most operations are very fast once the data
is in the registers. If the vector is instead not stored in contiguous
memory, with each variable in the next memory location, then the
subsequent 7 memory loads <strong>X<sub>2</sub>-X<sub>8</sub></strong>
and <strong>Y<sub>2</sub>-Y<sub>8</sub></strong> will take 20-33 ns each
instead of 0.3-1 ns each. This means that we need to ensure that
variables we are using are in contiguous memory whenever possible. There
will be an exercise at the end of this section where you will measure
the difference in execution time between these two cases.</p>
<p>Now let’s look at a simple matrix multiplication algorithm which is
fairly simple to program, but may have very different performance
depending on how you write the code.</p>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" aria-labelledby="nav-tab-2-Python" role="tabpanel">
<figure><img src="fig/matmult_fig.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" aria-labelledby="nav-tab-2-R" role="tabpanel">
<p>Need fig/matmult_fig-1-N.jpg.</p>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" aria-labelledby="nav-tab-2-C" role="tabpanel">
<figure><img src="fig/matmult_fig.jpg" alt="Formula and diagram of a matrix multiply" class="figure mx-auto d-block"><div class="figcaption">Matrix multiplication C = A * B</div>
</figure>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" aria-labelledby="nav-tab-2-Fortran" role="tabpanel">
<p>Need fig/matmult_fig-1-N.jpg.</p>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" aria-labelledby="nav-tab-2-Matlab" role="tabpanel">
<p>Need fig/matmult_fig-1-N.jpg.</p>
</div>
</div>
</div>
<p>Once the matrices are initialized, the code to multiply them together
is fairly simple.</p>
<div class="tabs">
<nav><div id="nav-tab-3" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-3-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Python" type="button" role="tab" aria-controls="nav-tabpanel-3-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-3-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-R" type="button" role="tab" aria-controls="nav-tabpanel-3-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-C" type="button" role="tab" aria-controls="nav-tabpanel-3-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-3-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-3-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-3" class="tab-content">
<div id="nav-tabpanel-3-Python" class="tab-pane show active" aria-labelledby="nav-tab-3-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>        C[i][j] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ):</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>            C[i][j] <span class="op">+=</span> A[i][k] <span class="op">*</span> B[k][j]</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-3-R" class="tab-pane" aria-labelledby="nav-tab-3-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-C" class="tab-pane" aria-labelledby="nav-tab-3-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-Fortran" class="tab-pane" aria-labelledby="nav-tab-3-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-Matlab" class="tab-pane" aria-labelledby="nav-tab-3-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>But if we are concerned about performance, we need to take a better
look at this code. Python is a row-major language like C/C++, which
means matrices like this are stored by rows first as in the picture
above. If we look at this code from a cache-line point of view, then it
looks optimal for the B matrix since when we load an element the others
in the cache line will get used in the next loop iterations, but the A
matrix is the opposite where elements being used next are farther
apart.</p>
<p>But it turns out this isn’t really the way to look at performance in
this case. For each element of C that we calculate, we will need N
elements of A and N elements of B. So every element of A and every
element of B will get re-used N times during this calculation. What is
important is that when we pull each element into the L1 cache where it
is the fastest to access, we want to re-use it as much as possible
rather than having to pull it repeatedly from the lower caches or main
memory.</p>
<p>An optimal approach has been developed in the past that pulls blocks
of each matrix into L1 cache. This block optimization results in a much
more complicated code, but also a much higher performing one. The good
news is that for users like us, we don’t have to ever program it
ourselves, we just need to know that it is in optimized libraries that
we can call at any time. Below are some examples of how to access the
low-level optimized libraries in the various languages.</p>
<div class="tabs">
<nav><div id="nav-tab-4" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-4-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Python" type="button" role="tab" aria-controls="nav-tabpanel-4-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-4-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-R" type="button" role="tab" aria-controls="nav-tabpanel-4-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-C" type="button" role="tab" aria-controls="nav-tabpanel-4-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-4-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-4-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-4" class="tab-content">
<div id="nav-tabpanel-4-Python" class="tab-pane show active" aria-labelledby="nav-tab-4-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>C <span class="op">=</span> np.matmult( A, B )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-4-R" class="tab-pane" aria-labelledby="nav-tab-4-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-4-C" class="tab-pane" aria-labelledby="nav-tab-4-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-4-Fortran" class="tab-pane" aria-labelledby="nav-tab-4-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-4-Matlab" class="tab-pane" aria-labelledby="nav-tab-4-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>So while writing a matrix multiplication code from scratch is not
difficult, using the optimized function accessible from each language is
easier and guarantees the best performance. To find out how much
difference there is in performance, you will need to try for yourself by
measuring the execution time for a few different matrix sizes in the
exercise below.</p>
<div id="measuring-cache-line-effects" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="measuring-cache-line-effects" class="callout-inner">
<h3 class="callout-title">Measuring Cache Line Effects<a class="anchor" aria-label="anchor" href="#measuring-cache-line-effects"></a>
</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-5" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-5-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-Python" type="button" role="tab" aria-controls="nav-tabpanel-5-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-5-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-R" type="button" role="tab" aria-controls="nav-tabpanel-5-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-C" type="button" role="tab" aria-controls="nav-tabpanel-5-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-5-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-5-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-5-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-5-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-5-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-5" class="tab-content">
<div id="nav-tabpanel-5-Python" class="tab-pane show active" aria-labelledby="nav-tab-5-Python" role="tabpanel">
<p>Run the dot_product.py code several times to get an average execution
time for a dot product between two vectors of 1 million elements each.
Try to run them on an isolated system if possible, or through a batch
queue that at least ensures the code is being run on an isolated
processing core. Then run the dot_product_sparse.py code in the same
manner for comparison. How much faster is the first code where the
vectors are stored in contiguous memory? How much faster should it
be?</p>
</div>
<div id="nav-tabpanel-5-R" class="tab-pane" aria-labelledby="nav-tab-5-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-5-C" class="tab-pane" aria-labelledby="nav-tab-5-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-5-Fortran" class="tab-pane" aria-labelledby="nav-tab-5-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-5-Matlab" class="tab-pane" aria-labelledby="nav-tab-5-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-6" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-6-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-Python" type="button" role="tab" aria-controls="nav-tabpanel-6-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-6-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-R" type="button" role="tab" aria-controls="nav-tabpanel-6-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-C" type="button" role="tab" aria-controls="nav-tabpanel-6-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-6-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-6-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-6-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-6-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-6-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-6" class="tab-content">
<div id="nav-tabpanel-6-Python" class="tab-pane show active" aria-labelledby="nav-tab-6-Python" role="tabpanel">
<p>Is the time difference what we expected? When I ran this on a new
Intel processor that did not have any other jobs running, I measured 180
milliseconds for the contiguous memory case and 1230 milliseconds for
the sparse case, resulting in a 6.9-times speedup by keeping the vector
in contiguous memory. Since a cache line is 64 Bytes and each element is
8 bytes, when the first element is loaded the next 7 are brought into L1
cache essentially for free since they are in contiguous memory.
Therefore we expect it to take 100 ns to load 8 elements of X, then 100
ns to load 8 elements of Y, then only a few ns to get each element into
the registers and do the computations. For the sparse vectors, it should
take 8 times as long since each load will take 100 ns. If you didn’t see
an 8-times speedup, don’t worry. The cache system is actually even more
complicated than this picture. Also remember that you may be sharing
parts of the processor with others. The main thing to learn here is that
if you take advantage of the cache line by keeping the vectors in
contiguous memory, your code will run faster.</p>
</div>
<div id="nav-tabpanel-6-R" class="tab-pane" aria-labelledby="nav-tab-6-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-6-C" class="tab-pane" aria-labelledby="nav-tab-6-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-6-Fortran" class="tab-pane" aria-labelledby="nav-tab-6-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-6-Matlab" class="tab-pane" aria-labelledby="nav-tab-6-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="time-different-matrix-multiplication-methods" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="time-different-matrix-multiplication-methods" class="callout-inner">
<h3 class="callout-title">Time Different Matrix Multiplication Methods<a class="anchor" aria-label="anchor" href="#time-different-matrix-multiplication-methods"></a>
</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-7" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-7-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-Python" type="button" role="tab" aria-controls="nav-tabpanel-7-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-7-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-R" type="button" role="tab" aria-controls="nav-tabpanel-7-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-C" type="button" role="tab" aria-controls="nav-tabpanel-7-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-7-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-7-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-7-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-7-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-7-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-7" class="tab-content">
<div id="nav-tabpanel-7-Python" class="tab-pane show active" aria-labelledby="nav-tab-7-Python" role="tabpanel">
<p>There are 2 separate codes supplied to perform the same matrix
multiplication for a given matrix size, matmult.py is raw Python code
and matmult_numpy.py uses the highly optimized
<strong>np.matmult()</strong> function. Both programs take the matrix
size as an argument, so you run using <strong>python matmult.py
100</strong> for example to measure the performance for multiplying two
100x100 matrices. Measure the performance for each method on a small
10x10 matrix, an intermediate sized 100x100 matrix, and a large
1000x1000 matrix to see how each is affected by the optimized
<strong>numpy</strong> function. You should run this through a batch
scheduler if at all possible since numpy will grab any cores it can, and
for a fair comparison we want to test out only the single-core
performance.</p>
</div>
<div id="nav-tabpanel-7-R" class="tab-pane" aria-labelledby="nav-tab-7-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-7-C" class="tab-pane" aria-labelledby="nav-tab-7-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-7-Fortran" class="tab-pane" aria-labelledby="nav-tab-7-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-7-Matlab" class="tab-pane" aria-labelledby="nav-tab-7-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-8" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-8-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-Python" type="button" role="tab" aria-controls="nav-tabpanel-8-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-8-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-R" type="button" role="tab" aria-controls="nav-tabpanel-8-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-C" type="button" role="tab" aria-controls="nav-tabpanel-8-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-8-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-8-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-8-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-8-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-8-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-8" class="tab-content">
<div id="nav-tabpanel-8-Python" class="tab-pane show active" aria-labelledby="nav-tab-8-Python" role="tabpanel">
<p>For the 10x10 matrix size there are 3 matrices having 100 elements
each needing 8 bytes storage, so storing all 3 matrices requires only
2.4 kB of memory. Everything fits entirely in L1 cache, so the block
optimized algorithm from <strong>numpy</strong> isn’t really needed. For
the 100x100 matrix size, 240 kB is needed to store all 3 matrices so
they will fit entirely in L2 cache, but not L1 cache. We therefore
expect a significant improvement by using the optimized
<strong>np.matmult()</strong> function. For the 1000x1000 matrix size,
we need 24 MB to store all 3 matrices so it will reside in L3 cache. The
<strong>np.matmult()</strong> function should speed up this run by
substantially more. The optimization of the <strong>numpy</strong>
routine however goes far beyond just block optimizing the algorithm so
that it reuses data in L1 cache though. There are also computational
optimizations that allow for many multiply-add operations to occur in
the same clock cycle, which is called vectorization. My measurements on
a modern Intel processor more of a performance benefit for larger matrix
sizes. For 1000x1000 matrices, the raw Python code was very slow at 6.5
MFlops (Million floating-point operations per second). All the
optimizations in the <strong>numpy</strong> code brought the performance
up to 15.4 GFlops, or a whopping 2354 times faster. Raw Python code is
fairly slow in itself because it is interpreted and not compiled like
C/C++/Fortran code, clearly you can do very well if you learn to use the
heavily optimized library routines. C is still faster than Python, with
raw C code reaching 1.6 GFlops and the optimized CBLAS DGEMM routine
reaching 91 GFlops.</p>
</div>
<div id="nav-tabpanel-8-R" class="tab-pane" aria-labelledby="nav-tab-8-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-8-C" class="tab-pane" aria-labelledby="nav-tab-8-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-8-Fortran" class="tab-pane" aria-labelledby="nav-tab-8-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-8-Matlab" class="tab-pane" aria-labelledby="nav-tab-8-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="advanced-exercise---transpose-b-to-cache-line-optimize-it" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="advanced-exercise---transpose-b-to-cache-line-optimize-it" class="callout-inner">
<h3 class="callout-title">Advanced Exercise - Transpose B to cache-line optimize it<a class="anchor" aria-label="anchor" href="#advanced-exercise---transpose-b-to-cache-line-optimize-it"></a>
</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-9" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-9-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-9-Python" type="button" role="tab" aria-controls="nav-tabpanel-9-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-9-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-9-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-9-R" type="button" role="tab" aria-controls="nav-tabpanel-9-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-9-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-9-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-9-C" type="button" role="tab" aria-controls="nav-tabpanel-9-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-9-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-9-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-9-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-9-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-9-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-9-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-9-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-9-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-9-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-9" class="tab-content">
<div id="nav-tabpanel-9-Python" class="tab-pane show active" aria-labelledby="nav-tab-9-Python" role="tabpanel">
<p>As k is incremented in the innermost loop, elements of A are being
brought into cache efficiently since they are stored in contiguous
memory, as we learned from the dot product example. Unfortunately,
elements of B are not since they will be sparse, separated by N-1
elements each time. While we already know that we can simply use the
numpy routine <strong>np.matmult()</strong> to optimize the code, if
this wasn’t available one thing we’d consider is to transpose the B
matrix so that it is stored in column-major format before doing the
matrix multiplication. If you’re up for a challenge, try programming
this up to see if it improves the performance compared to the original
Python code.</p>
</div>
<div id="nav-tabpanel-9-R" class="tab-pane" aria-labelledby="nav-tab-9-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-9-C" class="tab-pane" aria-labelledby="nav-tab-9-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-9-Fortran" class="tab-pane" aria-labelledby="nav-tab-9-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-9-Matlab" class="tab-pane" aria-labelledby="nav-tab-9-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-10" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-10-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-10-Python" type="button" role="tab" aria-controls="nav-tabpanel-10-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-10-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-10-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-10-R" type="button" role="tab" aria-controls="nav-tabpanel-10-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-10-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-10-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-10-C" type="button" role="tab" aria-controls="nav-tabpanel-10-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-10-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-10-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-10-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-10-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-10-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-10-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-10-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-10-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-10-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-10" class="tab-content">
<div id="nav-tabpanel-10-Python" class="tab-pane show active" aria-labelledby="nav-tab-10-Python" role="tabpanel">
<p>There are a great many levels of optimization that can be done to the
matrix multiplication algorithm. Transposing B should improve the
performance some. For a more complete overview of what is done in the
<strong>np.matmult()</strong> algorithm and others like it, follow the
link: <a href="https://en.algorithmica.org/hpc/algorithms/matmul/" class="external-link uri">https://en.algorithmica.org/hpc/algorithms/matmul/</a></p>
</div>
<div id="nav-tabpanel-10-R" class="tab-pane" aria-labelledby="nav-tab-10-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-10-C" class="tab-pane" aria-labelledby="nav-tab-10-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-10-Fortran" class="tab-pane" aria-labelledby="nav-tab-10-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-10-Matlab" class="tab-pane" aria-labelledby="nav-tab-10-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>When it starts taking longer to run a given program, we need to start
looking beyond just whether it gives the correct answer and begin
considering performance. This means we need to go beyond the conceptual
view of how the program runs to look at how it makes use of the
underlying hardware architecture. While this can get very complicated
very quickly, most users just need to be aware of where performance
bottlenecks can occur in order to avoid them. Quite often, writing
optimal code just means taking advantage of highly optimized libraries
that experts have written and tuned. So most of us just need to know
when and where to look for these optimized routines in order to write
highly optimized code.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>A computer’s view of code is more complex than a user’s view.</li>
<li>It’s important to understand a little about what goes on when code
actually runs, but you don’t need to be able to program at that
level.</li>
<li>Whenever possible, use code written and optimized by experts instead
of writing your own version.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-parallel-concepts"><p>Content from <a href="parallel-concepts.html">Parallel Computing Concepts</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/parallel-concepts.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Now that we can profile programs to find where the time is being
spent, how do we speed the code up?</li>
<li>What is parallel computing, and what are the underlying concepts
that make it work?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn different approaches to speeding up code.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>In the last chapter we learned how to profile a program to understand
where the time is being spent. In this section, we will talk more about
how to improve the performance of different parts of a program. This may
involve steering clear of inefficient methods in some computer
languages, minimizing the operation count, using optimized libraries,
and applying multiple cores or even multiple compute nodes to speed up
each computational part. Computations can sometimes be sped up
enormously using accelerators like GPUs (Graphic Processing Units) as
well. Reducing or eliminating IO can sometimes help, but ensuring that
the IO is done without costly locks, and to a file server that is not
overly used, can often help performance greatly as well.</p>
<section><h2 class="section-heading" id="optimizing-scalar-code">Optimizing Scalar Code<a class="anchor" aria-label="anchor" href="#optimizing-scalar-code"></a>
<a class="anchor" aria-label="anchor" href="#optimizing-scalar-code"></a>
</h2>
<hr class="half-width">
<p>Programming in languages like C/C++ and Fortran produces fairly
efficient code in general because these are compiled languages. In other
words, you need to compile the code before executing it, and the
compilers do very intricate optimizations to ensure the resulting
executable is highly efficient. Interpretive languages like Python, R,
and Matlab only do some compilation on the fly. They are therefore much
less optimized, but more convenient to run. We have already learned the
importance of using optimized library routines whenever possible, but
this is especially true for the interpretive languages. Some languages
also have certain methods that are convenient, but very inefficient, and
what to avoid and how to get around them will be discussed in later
chapters.</p>
<p>One thing that can help in understanding performance is to know how
much it costs to perform different common math functions. We can express
the speed of a code in GFlops, or Giga (Billion) Floating-point
operations per second. A floating-point operation involves two operands
that are typically 64-bit floats. When counting the Flops, we ignore
integer arithmetic and comparisons since those are very fast in relation
to the floating-point operations. Below is a table of the Flop cost for
each operation. This can be thought of as for example how many
operations does it take to do a cosine function, since the cosine is
done using a math library.</p>
<table class="table">
<thead><tr class="header">
<th align="center">Function / Operation</th>
<th align="center">Flops count</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">* + -</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">/</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center">square root</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">sin()/cos()/tan()</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="center">exponent()</td>
<td align="center">14</td>
</tr>
</tbody>
</table>
<p>One example of how this knowledge can help is if you have a large
loop where you are dividing by 4.0. Instead, you reduce the operation
count by 3 if you multiply by 0.25. This is not needed in compiled
languages like C/C++ or Fortran since the compiler does this
optimization for you, but it can help in the interpretive languages. The
example below reduces the floating-point operation count by removing the
redundant calculation of theta and replacing the expensive calculations
of the cosine and sine by using an iterative method using trigonometric
identities.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-1-Python">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">#    using Flops minimization to optimize code for performance</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>    <span class="co"># Define the number of frequencies and zero the array before summation</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>freq_real <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( NQ ) ]</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>freq_imag <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( NQ ) ]</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>    <span class="co"># Sum over each atom in the simulation</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_atoms ):</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    dx <span class="op">=</span> x[i] <span class="op">-</span> y[i]</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>        <span class="co"># Sum over the frequencies</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>    <span class="cf">for</span> iq <span class="kw">in</span> <span class="bu">range</span>( NQ ):</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>        theta <span class="op">=</span> <span class="fl">2.0</span> <span class="op">*</span> PI <span class="op">*</span> dx <span class="op">*</span> iq <span class="op">/</span> NQ</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>        freq_real[iq] <span class="op">+=</span> cos( theta )</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>        freq_imag[iq] <span class="op">+=</span> sin( theta )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-R">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-C">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Fortran">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-2-Python">
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># This is just partial code to demonstrate the mechanics of</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">#    using Flops minimization to optimize code for performance</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    <span class="co"># Define the number of frequencies and zero the array before summation</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>freq_real <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( NQ ) ]</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>freq_imag <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( NQ ) ]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>d_theta <span class="op">=</span> <span class="fl">2.0</span> <span class="op">*</span> PI <span class="op">*</span> dx <span class="op">/</span> NQ</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    <span class="co"># Sum over each atom in the simulation</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_atoms ):</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    dx <span class="op">=</span> x[i] <span class="op">-</span> y[i]</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>        <span class="co"># Calculate cos/sin of the theta increment and set starting cos/sin values</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>    cos_d_theta <span class="op">=</span> cos( d_theta )</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>    sin_d_theta <span class="op">=</span> sin( d_theta )</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>    cos_theta <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>    sin_theta <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>        <span class="co"># Sum over the frequencies</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>    <span class="cf">for</span> iq <span class="kw">in</span> <span class="bu">range</span>( NQ ):</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>        cos_new <span class="op">=</span> cos_theta <span class="op">*</span> cos_d_theta <span class="op">-</span> sin_theta <span class="op">*</span> sin_d_theta</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>        sin_theta <span class="op">=</span> sin_theta <span class="op">*</span> cos_d_theta <span class="op">+</span> cos_theta <span class="op">*</span> cos_d_theta</span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>        cos_theta <span class="op">=</span> cos_new</span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>        freq_real[iq] <span class="op">+=</span> cos_theta</span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a>        freq_imag[iq] <span class="op">+=</span> sin_theta</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-R">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-C">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Fortran">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>This is however a very over-simplified picture since it involves just
analyzing one factor. In practice, most processors can overlap
calculations for better speed like in the AVX vector instruction sets of
the Intel and AMD x86 architectures.</p>
<div id="flops-count" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="flops-count" class="callout-inner">
<h3 class="callout-title">Flops count<a class="anchor" aria-label="anchor" href="#flops-count"></a>
</h3>
<div class="callout-content">
<p>Count the floating-point operations (Flops) in the unoptimized and
optimized versions of the code above and calculate the expected speedup
rate.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>The unoptimized code uses <strong>N_atoms * ( 1 + 21 * NQ )
Flops</strong>. The optimized version uses <strong>N_atoms * ( 13 + 6 *
NQ ) Flops</strong>. For large NQ the speedup would be around 21/6 or
<strong>3.5 times</strong>.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="parallelizing-code">Parallelizing Code<a class="anchor" aria-label="anchor" href="#parallelizing-code"></a>
<a class="anchor" aria-label="anchor" href="#parallelizing-code"></a>
</h2>
<hr class="half-width">
<p>It is always good to optimize a scalar code first, but if you still
need your code to run faster then one option is to use more processing
power. This means using more then one computational core with each core
working on a different part of the data. The goal is to get a speedup of
N times if you are using N cores, though often parallel programs will
fall short of this ideal.</p>
<p>There are two main types of parallel programming. The first is
multi-core or shared-memory programming. This is the easiest approach,
with a single program running but for computationally demanding sections
like loops multiple threads are used with typically one thread on each
computational core. In this way, the scalar part of the code does not
need to be altered and we only need to put parallelizing commands before
each loop to tell the computer how to divide the problem up. It is
called <strong>shared-memory</strong> because all threads operate on the
data that is shared in main memory. This is the easiest approach, is
often very efficient, but has the limitation that it needs to work only
on a single compute node. Multi-threading in C/C++ and Fortran use the
<strong>OpenMP</strong> package, Python uses a simplified version of
this called <strong>pymp</strong>, and R allows for this through the
<strong>mclapply()</strong> function.</p>
<p>If you need even more computational power, or need access to more
memory than is on a single node, then you need to use multi-node
computing. This is also referred to as distributed-memory computing
since each thread in this case is its own separate but identical
program, again just operating on a different part of the data.
Distributed-memory programs can be run on a single compute node when
needed, but are designed to run on very large numbers of nodes at the
same time. Some programs have been run on millions of compute nodes, or
some of the largest HPC systems in the world which may cost more than
$100 million. C/C++ and Fortran codes use MPI, the Message-Passing
Interface, launching all the copies of the program to the different
nodes using the <strong>mpirun</strong> command, then each node shakes
hands with the others with the <strong>MPI_Init()</strong> function.
Each thread or task will operate on a different part of the data, and
when data needs to be exchanged the programmer can use MPI commands like
<strong>MPI_Send()</strong> and <strong>MPI_Recv()</strong> to pass
blocks of data to other threads. This is a very powerful way to program,
but it is definitely much more complicated too. Python has the
<strong>mpi4py</strong> package which is a stripped down version of MPI,
but unfortunately you cannot do multi-node computing with R.</p>
<p>You will not be taught how to program in these parallel languages in
this course, but you will be shown how to recognize each type of
parallel approach and how to work with each efficiently.</p>
</section><section><h2 class="section-heading" id="parallel-computing-concepts">Parallel Computing Concepts<a class="anchor" aria-label="anchor" href="#parallel-computing-concepts"></a>
<a class="anchor" aria-label="anchor" href="#parallel-computing-concepts"></a>
</h2>
<hr class="half-width">
<p>The syntax for doing parallel processing is different for
multi-threaded and multi-node programming, and also can vary for each
language, but handling multiple threads at the same time always involves
some of the same basic underlying concepts. Understanding the basic
concepts underlying these methods will help us to understand the
functions at the language level themselves.</p>
<div class="section level3">
<h3 id="locks-in-programs-and-file-systems">Locks in Programs and File Systems<a class="anchor" aria-label="anchor" href="#locks-in-programs-and-file-systems"></a>
</h3>
<p>A multi-threaded program uses shared-memory where many threads may
want to access the same data at the same time. If they are all reading
the data, this is not a problem. However, if even one thread wants to
change the data by writing to it while other threads may be reading it,
this can lead to uncertain results depending on which thread does its
read or write first. This uncertainty must therefore always be avoided,
and often it is handled by locking memory when a write occurs so that
only that one thread has access at that time.</p>
<p>The same thing can happen in parallel file servers where there are
multiple paths being exploited to the same data file in order to provide
better performance. If multiple threads, or even multiple programs, are
reading the same file or different files in the same directory then
everything is fine. However, if one of those is writing to a file then a
parallel file server will lock the entire directory down to prevent
other threads from reading until the write is completed. This is
something that every user needs to be aware of. It only applies to
parallel file servers, so local disk (/tmp) has no problems with this
since there is only one controller for the disk, while a parallel file
server has many controlling nodes. Some scratch space also can handle
multiple writes to the same directory without locking. Since this can
have severe impacts on performance, it is always good to ask your system
administrator if you don’t know. Ways around this include switching to a
different file system like /tmp while running the job, or putting the
files in different directories.</p>
</div>
<div class="section level3">
<h3 id="barriers">Barriers<a class="anchor" aria-label="anchor" href="#barriers"></a>
</h3>
<p>Since distributed-memory programs involve multiple copies of the same
code, we commonly need to ensure that all are at the same point in the
code. MPI uses barriers for this, an <strong>MPI_Barrier()</strong>
function to be exact. When this is encountered, each task will stop and
wait until all tasks reach that point in the code, they will communicate
this to each other, then continue on. A common example of why you would
need this would be in debugging an MPI code where you want to identify
where the code may be failing. If one task gets ahead of the other and
errors out, it may be that the root task will be at a different place in
the code and report that line where the job failed.</p>
</div>
<div class="section level3">
<h3 id="forks">Forks<a class="anchor" aria-label="anchor" href="#forks"></a>
</h3>
<p>All multi-threaded packages use some sort of a fork function. When a
loop is encountered and the root thread needs to spin up multiple
threads to do the work, it does so by doing a <strong>fork()</strong>
which duplicates the variables in the root thread. This is done
virtually which may be a bit confusing. If every piece of data was
copied it would increase the memory usage enormously for runs on large
numbers of cores, so only the pointers to the arrays are copied. If the
data is only being read then all threads can read from the original
array. If any thread writes to part of an array, then a unique copy of
that part of the array is made for that thread only. So the fork process
manages the memory usage behind the scenes to minimize the redundant
storage of data, but ensures that there is no need for a memory lock
when a thread writes to that data by making a copy instead.</p>
</div>
<div class="section level3">
<h3 id="dependencies-in-loops">Dependencies in Loops<a class="anchor" aria-label="anchor" href="#dependencies-in-loops"></a>
</h3>
<p>All those mechanisms discussed above may be used in implementing a
parallel computing package. As a user, what we really need to know is
when can a section of a program be parallelized. If you look at the
loops where the most computational time is being spent, what you need to
determine is whether each pass through the loop is independent of the
others, or whether each pass is dependent on the results of the previous
iteration. If each pass through a loop can be done independently of the
others, then we can do them at the same time. This is a simple
statement, but it does sometimes take more thinking to understand if
there are any dependencies involved. If you have any doubt, try writing
down all the variables that are needed as input for each iteration of
the loop, then see if any of those change throughout the loop.</p>
<p>If you have a program with nested loops, you may need to analyze each
loop level to see if it is parallelizable. Parallelizing the outer loop
means that there will be more computations for each thread or task,
which is referred to as being more coarse grained. This can lead to much
higher efficiencies, but it is not always possible. Often it is the
inner loop that is easiest to parallelize, and this is most often the
case with multi-threaded parallelism.</p>
</div>
</section><section><h2 class="section-heading" id="using-accelerators-like-gpus">Using Accelerators like GPUs<a class="anchor" aria-label="anchor" href="#using-accelerators-like-gpus"></a>
<a class="anchor" aria-label="anchor" href="#using-accelerators-like-gpus"></a>
</h2>
<hr class="half-width">
<p>Some programs can be sped up by using a GPU as a computational
accelerator. A 32-bit GPU is the same as you would buy for a high-end
gaming computer and can cost $1000-$1500. These are ideal for
accelerating 32-bit codes like classical molecular dynamics simulations,
and have custom hardware that is great for training AI (Artificial
Intelligence) neural networks or machine learning models. The more
expensive 64-bit GPUs are never intended for graphics at all. They are
custom designed as accelerators even though they are still called GPUs.
These currently cost around $11,000 for an NVIDIA A100 and around twice
that for a newer H100.</p>
<p>Writing a program to run on a GPU is very difficult. For NVIDIA GPUs,
you use a programming language called CUDA. There are many fewer codes
optimized for AMD GPUs at this point. They are programmed with Hip which
can be compiled to run on either AMD or NVIDIA GPUs. There are also
projects in development to convert native CUDA codes into executables
optimized for AMD GPUs.</p>
<p>Running a job with a GPU accelerator is not that difficult. If your
application can make use of one or more GPUs, there will be directions
on how to specify the number of GPUs. If you are on an HPC system, you
can request the number and type of GPUs you want for each job.</p>
</section><section><h2 class="section-heading" id="optimizing-input-and-output">Optimizing Input and Output<a class="anchor" aria-label="anchor" href="#optimizing-input-and-output"></a>
<a class="anchor" aria-label="anchor" href="#optimizing-input-and-output"></a>
</h2>
<hr class="half-width">
<p>The first thing to understand about IO (Input and Output) is that it
can make a big difference as to what type of a file system you are
reading from or writing to. Local disk (usually /tmp) is temporary
storage and has size restrictions, and it isn’t as fast as a parallel
file server that stripes data across many disks at the same time, but it
is still sometimes the best to use if others are heavily using the main
file server and slowing it down. As good as parallel file severs are,
they also commonly need to lock a directory if more than one file is
being written at the same time. Any locking can slow the performance of
a code down immensely and should be avoided if at all possible. Many HPC
systems may have fast scratch space which is temporary storage often
purged every week or month but very large in size. This is designed for
use when you are running your job, and may also not suffer from the same
locking issues as on some parallel file servers.</p>
<p>On our HPC system at Kansas State University, our fast scratch is
about ten times as fast as the parallel file server system that our home
directories are on. So you would think that all you have to do is use
fast scratch all the time to make your IO ten times faster. It actually
is the case if you are streaming data in, by which we mean reading in
data in large chunks that do not need to be converted. Files with large
strings like genetic information fall into this category since the
strings can be hundreds or thousands of characters long and the
representation in the file is the same as in the program. Reading in
arrays of floats or integers from binary files also can go as fast as
the file server allows since the elements are stored in binary in both
the file and the program.</p>
<p>The problem comes when we want to store numbers for example in a text
file so we can see them ourselves. When we write them or read them, the
process goes slow since we have to convert each number from its binary
representation into a text string before reading or writing. With IO, it
is that conversion process which is slow, so it doesn’t matter how fast
the underlying file server is in these cases. So if you want to speed up
IO, think about streaming data in binary form if possible, and if so
then choose the fastest file server available.</p>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout-inner">
<h3 class="callout-title">Scaling Study of the Distributed-Memory Dot Product Code<a class="anchor" aria-label="anchor" href="#scaling-study-of-the-distributed-memory-dot-product-code"></a>
</h3>
<div class="callout-content">
<p>Measure the entire run-time for the dot_product_message_passing code
for the language you are working with for 1, 4, 8, and 16 cores if you
are on an HPC system with at least 2 compute nodes. You can try
different combinations of nodes and cores for each if you would like to
see the effects of the network (for the 4 cores, try 2 nodes 2 cores vs
4 nodes 1 core).</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>In this code we initialize the vectors locally so there is no
communication involved. The only communication is the global sum at the
end, so we expect the scaling to be close to ideal. In many practical
MPI codes, we would need to read data into one of the ranks, divide the
data up and send it out to each other node. Real MPI applications also
usually require communication mixed in with the computational part in
order to get data where it needs to be. All this communication can slow
down the job, and this usually gets worse as you spread a job over more
cores, and especially over more nodes.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>What techniques can be used to speed up scalar code?</li>
<li>How to improve input and output?</li>
<li>Learn about the difference between multi-core and multi-node
programs.</li>
<li>Understand the fundamentals of locks, barriers, and forks.</li>
<li>Practice doing a scaling study.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-multi-threaded"><p>Content from <a href="multi-threaded.html">Multi-Threaded Programs</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/multi-threaded.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the multi-threaded shared-memory programming model?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn about multi-threaded computing and how to use it.</li>
<li>Understand the strengths and limitations of this approach.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>Most computer languages have the ability to do multi-threaded
computing. C/C++ and Fortran use the OpenMP package which is by far the
most well developed. It uses pragma statements to control the
parallelization of loops so that multiple compute cores work at the same
time on different parts of the data. OpenMP is not only extremely
efficient, but it also provides very advanced features offering greater
control on how the parallelization is to be done, all without
encumbering the programmer too much. The <strong>pymp</strong> package
for Python is a stripped down version of OpenMP supporting just the
basic functionality. It is an actively developed project and is very
efficient and relatively easy to use as well. R takes a very different
approach in doing multi-threading using the <strong>mclapply()</strong>
function which is a multi-core replacement for the
<strong>lapply()</strong> function. This operates similarly to OpenMP
and pymp but uses a very different syntax. It is also not nearly as
efficient and requires some non-default choices to make it more perform
better. Matlab also uses a different syntax in its Parallel Computing
Toolbox where it uses a <strong>parfor</strong> command to do a parallel
<strong>for</strong> loop.</p>
<p>All of these methods behave basically the same by forking, or
splitting off, extra compute threads when called. Each thread gets its
own virtual memory space, meaning most large arrays are not copied
during the initialization stage. If any thread writes to an array, only
then is that array copied to that thread’s memory, and only the page of
memory (4096 Bytes) that has been changed. This is called a
<strong>copy-on-write</strong> method and is handled by the operating
system. Forking is very efficient in this way, only doing the work it
needs. For Python, this gets around the Global Interface Lock which is
designed to protect python objects. Unfortunately the Windows operating
system itself does not have support for the <strong>fork</strong>
function so you cannot run multi-threaded Python codes like
<strong>pymp</strong> on Windows, at least from the Power Shell.
However, if you have the Windows Subsystem for Linux (WSL) installed
this provides a robust Linux system that bypasses Windows and its
limitations so <strong>pymp</strong> codes can be run in this
manner.</p>
<p>The figure below illustrates how multi-threading works on a dot
product between two vectors. Since the program uses shared-memory, the
initialization is done entirely on the main thread of processor 1. Then
each of 4 threads in this example does a partial sum on the vector
elements it is responsible for, so all 4 threads are running at the same
time but operating on different parts of the data. After they have all
completed their parts of the computation, the master thread sums all the
partial sums into the dot product and prints it out.</p>
<figure><img src="fig/multi-threaded-dot-product-0.jpg" alt="Shared-memory multi-threaded dot product showing the memory layout of both vectors" class="figure mx-auto d-block"><div class="figcaption">Diagram of a shared-memory multi-threaded dot
product</div>
</figure><div class="section level3">
<h3 id="the-multi-threaded-dot-product-code">The multi-threaded dot product code<a class="anchor" aria-label="anchor" href="#the-multi-threaded-dot-product-code"></a>
</h3>
<p>Let’s go through the multi-threaded version of the dot product code
dot_product_threaded.py below to illustrate the changes that had to be
made to the code to parallelize it. We should first note that we need to
install the <strong>pymp</strong> package into our virtual environment
by doing <strong>pip install pymp-pypi</strong>. Once that is installed,
the <strong>import pymp</strong> line will bring those functions into
the code.</p>
<p>When we run the code we will want to set the number of threads for it
to use. In the code below, this is being set internally using the number
of threads passed in as a command line argument. This is used to set the
number of threads using the <strong>pymp.config.num_threads</strong>
variable. The other method of setting the number of threads is to use
the environmental variable <strong>PYMP_NUM_THREADS</strong> externally.
For example, in your job script you can have a line <strong>export
PYMP_NUM_THREADS=4</strong> to tell the program to use 4 threads.</p>
<p>Right before the loop we must define our parallel environment with
the line <strong>with pymp.Parallel( nthreads ) as p:</strong> which
spins up the threads with the fork method. Then the for loop range is
changed so that each thread has a different range for the elements of
the loop that each thread is responsible for.</p>
<p>In the OpenMP multi-threading package used with C/C++ and Fortran,
you can use the same variable d_prod in the loop and just declare it as
a variable to be used locally within each thread then globally summed at
the end, which is called a <strong>reduction</strong>. This is very
convenient and requires fewer changes to the code, but the pymp package
does not support this added function by choice opting for the Python way
of doing it more explicitly, so in our code we need to create a shared
array of partial sums and manually sum them together at the end. This is
just as efficient computationally, it just takes a little extra coding
but is more explicit.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-1-Python">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Do the dot product between two vectors X and Y then print the result</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># USAGE:  python dot_product_threaded.py 4       to run on 4 threads</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> pymp</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>   <span class="co"># Get and set nthreads from the command line</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>pymp.config.num_threads <span class="op">=</span> <span class="bu">int</span>( sys.argv[<span class="dv">1</span>] )</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>nthreads <span class="op">=</span> pymp.config.num_threads</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100000000</span>      <span class="co"># Do a large enough test to reduce timing variance</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>x <span class="op">=</span> [ <span class="bu">float</span>( i ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>y <span class="op">=</span> [ <span class="bu">float</span>( i ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N ) ]</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>   <span class="co"># Now initialize a very large dummy array to force X and Y out of all levels of cache</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>   <span class="co">#    so that our times are for pulling elements up from main memory.</span></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>dummy <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( <span class="dv">125000000</span> ) ]  <span class="co"># Initialize 1 GB of memory</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>   <span class="co"># Now we start our timer and do our calculation using multiple threads</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>psum <span class="op">=</span> pymp.shared.array( (nthreads,), dtype<span class="op">=</span><span class="st">'float'</span> )</span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( nthreads ):</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a>   psum[i] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a>d_prod <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a><span class="cf">with</span> pymp.Parallel( nthreads ) <span class="im">as</span> p:</span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a>   <span class="cf">for</span> i <span class="kw">in</span> p.<span class="bu">range</span>( N ):</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a>      <span class="co">#d_prod += x[i] * y[i]</span></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>      psum[p.thread_num] <span class="op">+=</span> x[i] <span class="op">*</span> y[i]</span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( nthreads ):     <span class="co"># Explicitly do the reduction across threads</span></span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a>   d_prod <span class="op">+=</span> psum[i]</span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a>t_elapsed <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a>   <span class="co"># The calculation is done and timer stopped so print out the answer</span></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'dot product = '</span>, d_prod, <span class="st">'took '</span>, t_elapsed, <span class="st">' seconds'</span> )<span class="op">;</span></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a><span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">1.0e-9</span> <span class="op">/</span> t_elapsed, <span class="st">' Gflops (billion floating-point operations per second)'</span>)</span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a><span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">8.0</span><span class="op">/</span><span class="fl">1.0e9</span>, <span class="st">' GB memory used'</span> )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-R">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-C">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Fortran">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-1-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>So parallelizing this program really only requires us to change
around 11 lines of code, and from that we get the benefit of being able
to apply much greater computing power. We do have some control over how
the parallelization works internally. Using <strong>p.range(N)</strong>
in our for loop will use static scheduling where each thread is
responsible for a pre-determined set of indices at regular intervals as
in the figure above. If instead we use <strong>p.xrange(N)</strong> then
dynamic scheduling will be used where each index will be assigned to the
next available thread. This can be very useful if the amount of work in
each pass through the loop varies greatly. Dynamic scheduling can
produce much more efficient results in cases where there is a great load
imbalance.</p>
</div>
<div class="section level3">
<h3 id="understanding-what-can-cause-inefficient-scaling">Understanding what can cause inefficient scaling<a class="anchor" aria-label="anchor" href="#understanding-what-can-cause-inefficient-scaling"></a>
</h3>
<p>A scaling study is designed to expose inefficiencies in a parallel
code and to determine how many cores to use for a given problem size.
That last part is important to understand. If there is too little work
in each iteration of a loop, then loop overhead can limit scaling.
Calculations on larger data sets usually scale better.</p>
<p>A loop may be very scalable in itself, but if there is too much time
spent in the scalar part of the code like initialization, doing the
reductions, or doing input at the beginning and output at the end, then
the entire code may not scale well. Load imbalance can also be a
problem. If the time it takes to pass through a loop varies, then using
dynamic scheduling is very important.</p>
<p>Shared arrays are an extremely important part of multi-threaded
packages. Since they do involve the copy-on-write mechanism, they can
lead to inefficiency in the loop. In general this is minimal but
something to be aware of.</p>
<p>Multi-threading packages like <strong>OpenMP</strong> and
<strong>pymp</strong> provide mechanisms that force loops in the
algorithm out of multi-threaded operation and back into single-threaded
operation. This always leads to terrible scaling and should almost never
be used.</p>
<div id="scaling-study-of-the-multi-threaded-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="scaling-study-of-the-multi-threaded-dot-product-code" class="callout-inner">
<h3 class="callout-title">Scaling Study of the Multi-Threaded Dot Product Code<a class="anchor" aria-label="anchor" href="#scaling-study-of-the-multi-threaded-dot-product-code"></a>
</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-2-Python">
<p>Measure the execution time for the dot_product_threaded.py code for
1, 4, 8, and 16 cores. If possible, use a job script requesting 16 cores
and do all runs in the same job. You can look at the job scripts like
sb.ddot_py in the <strong>code</strong> directory as an example but your
job script will probably be different. Then calculate the speedup
compared to the scalar (single-core) run to see how close to ideal the
performance is.</p>
<p>If you want, you may also run a scaling study for the
<strong>matmult.py</strong> code.</p>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-R">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-C">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Fortran">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-2-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-3" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-3-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Python" type="button" role="tab" aria-controls="nav-tabpanel-3-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-3-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-R" type="button" role="tab" aria-controls="nav-tabpanel-3-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-C" type="button" role="tab" aria-controls="nav-tabpanel-3-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-3-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-3-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-3" class="tab-content">
<div id="nav-tabpanel-3-Python" class="tab-pane show active" role="tabpanel" aria-labelledby="nav-tab-3-Python">
<p>For this very simple problem, each thread can do its computations
totally independently. There is only a global sum of all the partial
sums at the end, so we would expect the scaling to be close to ideal. In
my measurements, I saw a 3.1x speedup on 4 cores, a 5.3x speedup on 8
cores, and a 7.8x speedup on 16 cores. For this problem, there just are
so few computations being done in each loop iteration, only 2
floating-point operations, that the loop overhead is preventing better
scaling. A C/C++ version of this code using OpenMP for multi-threading
runs 170 times faster because it is a compiled language, but likewise
does not scale well due to the few computations being done in each pass
through the loop.</p>
</div>
<div id="nav-tabpanel-3-R" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-R">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-C" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-C">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-Fortran" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-Fortran">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-Matlab" class="tab-pane" role="tabpanel" aria-labelledby="nav-tab-3-Matlab">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Multi-threaded computing is powerful and fairly easy to use but only
works on one compute node.</li>
<li>Understand key factors that can limit the efficient scaling of
multi-threaded programs.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://github.com/classner/pymp" class="external-link">github pymp</a></li>
<li><a href="https://hpc-tutorials.llnl.gov/openmp/" class="external-link">LLNL OpenMP
tutorial</a></li>
</ul>
</div></section><section id="aio-message-passing"><p>Content from <a href="message-passing.html">Message-Passing Programs</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/message-passing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the distributed-memory programming model?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn about message-passing in distributed-memory computing.</li>
<li>Understand the strengths and limitations of this approach.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="the-message-passing-paradigm">The Message-Passing Paradigm<a class="anchor" aria-label="anchor" href="#the-message-passing-paradigm"></a>
<a class="anchor" aria-label="anchor" href="#the-message-passing-paradigm"></a>
</h2>
<hr class="half-width">
<p>While multi-threaded parallelization is very efficient when running
on a single compute node, at times we need to apply even more compute
power to a single job. Since this will involve more than one compute
node, we will need a separate but identical program running on each
computer which leads us to a new programming paradigm. This is known by
various descriptive names including MPMD or Multiple Program Multiple
Data, but is more commonly known as message-passing which is how data is
exchanged between multiple identical copies of a program that each
operate on different data. There is a common syntax used which is
<strong>MPI</strong> or the <strong>Message-Passing Initiative</strong>
standard. C/C++ and Fortran have several MPI implementations including
free <strong>OpenMPI</strong> and <strong>MPICH</strong> libraries and
commercial <strong>Intel MPI</strong>, while Python uses
<strong>mpi4py</strong> which implements a stripped down version of the
MPI standard. R does not have any message-passing implementation though
there was work on <strong>Rmpi</strong> in the past that was never
completed.</p>
<p>The diagram below shows what a distributed-memory dot product looks
like on a multi-node computer in contrast to the shared-memory program
in the diagram in the previous chapter. In this case, our job is running
on 4 cores on node 1 and 4 cores on node 2. Distributed-memory means
that there will be 8 identical programs running, with 4 on each node,
but each will have responsibility for doing one eighth of the
calculations. We will need to use the <strong>mpirun</strong> or
<strong>mpiexec</strong> commands to launch eight copies of the program
on the two nodes then start them running. The jobs will handshake then
decide which part of the data each is responsible for. After all nodes
have calculated their partial sums, they will be globally summed across
all 8 tasks using the network if needed then the program with lowest
rank will print out the results.</p>
<div class="tabs">
<nav><div id="nav-tab-1" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-1-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Python" type="button" role="tab" aria-controls="nav-tabpanel-1-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-1-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-R" type="button" role="tab" aria-controls="nav-tabpanel-1-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-C" type="button" role="tab" aria-controls="nav-tabpanel-1-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-1-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-1-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-1-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-1-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-1-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-1" class="tab-content">
<div id="nav-tabpanel-1-Python" class="tab-pane show active" aria-labelledby="nav-tab-1-Python" role="tabpanel">
<figure><img src="fig/distributed-memory-dot-product-0.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-R" class="tab-pane" aria-labelledby="nav-tab-1-R" role="tabpanel">
<figure><img src="fig/distributed-memory-dot-product-1.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-C" class="tab-pane" aria-labelledby="nav-tab-1-C" role="tabpanel">
<figure><img src="fig/distributed-memory-dot-product-0.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-Fortran" class="tab-pane" aria-labelledby="nav-tab-1-Fortran" role="tabpanel">
<figure><img src="fig/distributed-memory-dot-product-1.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
<div id="nav-tabpanel-1-Matlab" class="tab-pane" aria-labelledby="nav-tab-1-Matlab" role="tabpanel">
<figure><img src="fig/distributed-memory-dot-product-1.jpg" alt="Distributed-memory dot product showing the layout of both vectors on both computers" class="figure mx-auto d-block"><div class="figcaption">Diagram of a distributed-memory multi-node dot
product on two computers</div>
</figure>
</div>
</div>
</div>
<p>In parallel computing, the programmer must decide how to divide the
data between the processes. In this case, we could have just as easily
decided that rank 0 is responsible for the first 1/8<sup>th</sup> of the
elements, rank 1 for the next 1/8<sup>th</sup>, etc. If we were reading
in the data and distributing it in blocks to each other process then
this would be better since we wouldn’t have to move the data around
before sending out each block of data. In this case for the dot product,
it simply doesn’t matter. Regardless of how the work is divided, it
sometimes does not come out evenly so you do have to make sure that all
work is accounted for even if some processes have to do slightly
more.</p>
<div class="section level3">
<h3 id="the-message-passing-dot-product-code">The message-passing dot product code<a class="anchor" aria-label="anchor" href="#the-message-passing-dot-product-code"></a>
</h3>
<p>Let’s look at how the message-passing version of the code differs
from the original scalar version and contrast it to the multi-threaded
version. If you are using Python, you first need to <strong>pip install
mpi4py</strong> into your virtual environment then you can
<strong>import mpi4py as MPI</strong> to bring the package into your
code.</p>
<p>Since a message-passing job is many identical copies of the same
program working on different data, we need to use the <strong>mpirun -np
4</strong> command for example to launch 4 copies of the code. If you
are running the job using a scheduler like Slur, this will run on the 4
cores that you requested. If you are not running through using a
scheduler, you can specify different compute node names such as
<strong>mpirun –host node1,node1,node2,node2</strong> to run on 2 cores
of node1 and 2 cores of node2. You can also specify a hostfile and
number of slots using <strong>mpirun –hostfile hostfilename</strong>
where the host file contains lines having the node name and number of
slots on that node (node1 slots=2).</p>
<p>All message-passing programs start with an initialization routine
which for Python is the <strong>comm = MPI.COMM_WORLD</strong> statement
and C/C++/Fortran is <strong>MPI_COMM_WORLD</strong>. This says that our
communicator includes all ranks available (COMM_WORLD), and it connects
with all the other programs. The other two lines that are at the start
of every message-passing program are functions to get the number of
ranks, the message-passing word for threads, and the rank for each
program which ranges from 0 to the number of ranks minus 1. This rank is
what the programmer uses to decide which data each copy of the program
will work on, and is also used to identify which copy of the program to
pass messages to.</p>
<p>Each rank is responsible for doing the dot product on part of the
data, and the programmer must decide on how to divide this work up. For
this code, we are going to divide the work up in a similar way to how
the multi-threaded program worked, where the rank 0 is responsible for
indices 0, nranks, 2<em>nranks, 3</em>nranks, etc. The initialization of
the X and Y vectors shows how we are now just dealing with N_elements
each (N/nranks) but we still want the initialization to be the same so
we have to change that a bit.</p>
<p>We do a barrier command before starting the timer so that all the
ranks are synchronized. Normally it is good practice to avoid barriers
in codes, but in our case we are doing it so we get a more accurate
timing.</p>
<p>Each rank calculates a partial sum of the indices that it is
responsible for. Then all ranks must participate in a reduction to
globally sum the partial sums. Notice at the end that we only have the
lowest print its results. If we didn’t protect the print statements like
this, we would get <strong>nranks</strong> copies of each print
statement.</p>
<div class="tabs">
<nav><div id="nav-tab-2" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-2-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Python" type="button" role="tab" aria-controls="nav-tabpanel-2-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-2-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-R" type="button" role="tab" aria-controls="nav-tabpanel-2-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-C" type="button" role="tab" aria-controls="nav-tabpanel-2-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-2-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-2-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-2-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-2-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-2-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-2" class="tab-content">
<div id="nav-tabpanel-2-Python" class="tab-pane show active" aria-labelledby="nav-tab-2-Python" role="tabpanel">
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Do the dot product between two vectors X and Y then print the result</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># USAGE:  mpirun -np 4 python dot_product_message_passing.py       to run on 4 tasks</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># pip install mpi4py      in your virtual environment before you run this code</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> mpi4py <span class="im">import</span> MPI</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>   <span class="co"># Get my rank and the number of ranks - (MPI talks about ranks instead of threads)</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a>comm <span class="op">=</span> MPI.COMM_WORLD       <span class="co"># Handshake with other ranks</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>nranks <span class="op">=</span> comm.Get_size()    <span class="co"># The number of ranks (threads)</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>myrank <span class="op">=</span> comm.Get_rank()    <span class="co"># Which rank am I ( 0 .. nranks-1 )</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100000000</span>      <span class="co"># Do a large enough test to reduce timing variance</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>N_elements <span class="op">=</span> <span class="bu">int</span>( N<span class="op">/</span>nranks )</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="cf">if</span> ( N <span class="op">%</span> nranks <span class="op">!=</span> <span class="dv">0</span> ):</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>   <span class="bu">print</span>(<span class="st">"Please use an even number of ranks"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>   exit</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>x <span class="op">=</span> [ <span class="bu">float</span>( myrank <span class="op">+</span> i<span class="op">*</span>nranks ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_elements ) ]</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>y <span class="op">=</span> [ <span class="bu">float</span>( myrank <span class="op">+</span> i<span class="op">*</span>nranks ) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_elements ) ]</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>   <span class="co"># Now initialize a very large dummy array to force X and Y out of all levels of cache</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>   <span class="co">#    so that our times are for pulling elements up from main memory.</span></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>dummy <span class="op">=</span> [ <span class="fl">0.0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( <span class="dv">125000000</span> ) ]  <span class="co"># Initialize 1 GB of memory</span></span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a>   <span class="co"># Now we start our timer and do our calculation using multiple threads</span></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a>comm.barrier()    <span class="co"># Sync all ranks before starting the timer</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a>t_start <span class="op">=</span> time.perf_counter()</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>psum <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( N_elements ):</span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a>   psum <span class="op">+=</span> x[i] <span class="op">*</span> y[i]</span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a>d_prod <span class="op">=</span> comm.<span class="bu">reduce</span>( psum, op<span class="op">=</span>MPI.SUM )</span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a>t_elapsed <span class="op">=</span> time.perf_counter() <span class="op">-</span> t_start</span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a>   <span class="co"># The calculation is done and timer stopped so print out the answer</span></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a><span class="cf">if</span> ( myrank <span class="op">==</span> <span class="dv">0</span> ):    <span class="co"># Only rank 0 will print results</span></span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a>   <span class="bu">print</span>(<span class="st">'dot product = '</span>, d_prod, <span class="st">'took '</span>, t_elapsed, <span class="st">' seconds on '</span>, nranks, <span class="st">' ranks'</span> )<span class="op">;</span></span>
<span id="cb1-47"><a href="#cb1-47" tabindex="-1"></a>   <span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">1.0e-9</span> <span class="op">/</span> t_elapsed, <span class="st">' Gflops (billion floating-point operations per second)'</span>)</span>
<span id="cb1-48"><a href="#cb1-48" tabindex="-1"></a>   <span class="bu">print</span>( <span class="fl">2.0</span><span class="op">*</span>N<span class="op">*</span><span class="fl">8.0</span><span class="op">/</span><span class="fl">1.0e9</span>, <span class="st">' GB memory used'</span> )</span></code></pre>
</div>
</div>
<div id="nav-tabpanel-2-R" class="tab-pane" aria-labelledby="nav-tab-2-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-C" class="tab-pane" aria-labelledby="nav-tab-2-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Fortran" class="tab-pane" aria-labelledby="nav-tab-2-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-2-Matlab" class="tab-pane" aria-labelledby="nav-tab-2-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
<p>If you want to other examples of MPI code, the scalar algorithm for a
matrix multiply is very simple but you can compare that to the
<strong>MPI</strong> versions in the links below. These algorithms are
much more complicated since you need to have particular columns and rows
in the same rank in order to perform the vector operations. This
involves a great deal of communication and the programmer must determine
the optimal way to handle the message passing to minimize the
communication costs and memory usage.</p>
<ul>
<li><a href="https://github.com/JordiCorbilla/mpi4py-examples/blob/master/src/examples/matrix%20multiplication/matrixmultiplication.py" class="external-link">MPI
matrix multiply in Python</a></li>
<li><a href="https://gist.github.com/AshanthaLahiru/bfa1a631f6af05af93e98538eeca3018" class="external-link">MPI
matrix multiply in C</a></li>
</ul>
<p>We see from all this that parallelizing a program using
message-passing requires much more work. This is especially true in more
complex programs where often you need to read input in on the lowest
rank and broadcast the data out to the other ranks. Most of the time
there is also a lot of communication needed during a calculation that
requires sending data from one rank to the other. In these cases, there
must be a pair of send and receive statements to specify the starting
data, what node to send it to, and on the receiving rank you must
specify the source rank and where to put the data. The nice thing about
message-passing is that the libraries do all the work of interacting
with the underlying communication system for you.</p>
<p>So while message-passing is more difficult to program, the supporting
libraries are very sophisticated in simplifying the process. With
multi-threading, your algorithm is limited to the number of cores on a
single compute node, but the message-passing model has no limits. People
have run message-passing codes on millions of cores on supercomputers
worth as much as half a billion dollars.</p>
</div>
<div class="section level3">
<h3 id="understanding-what-can-cause-inefficient-scaling">Understanding what can cause inefficient scaling<a class="anchor" aria-label="anchor" href="#understanding-what-can-cause-inefficient-scaling"></a>
</h3>
<p>In many practical message-passing codes, we would need to read data
into one of the ranks, divide the data up and send it out to each other
node. This extra communication is necessary but does lead to some
inefficiency to be aware of. Real message-passing applications also
usually require communication mixed in with the computational part in
order to move data to where it needs to be for the calculations.
Advanced programmers can try to minimize this by hiding the
communications behind the calculations using asynchronous communication
calls. All this communication can slow down the job, and this usually
gets worse as you spread a job over more cores, and especially over more
compute nodes. It is therefore usually best to keep the processes in a
run on as few compute nodes as possible so that most of the
communication is being done within a node by memory copies that are
faster than sending data between nodes across network cards.</p>
<p>Networks in cluster supercomputers like those typical in universities
are usually not uniform. Performance within a switch which may connect
32-40 compute nodes may be very fast, but if your job is spread on
different network switches it can be much slower since switches may be
connected to each other at much lower aggregate bandwidths. In Slurm you
can request that your job be run on just one switch by using
<strong>–switches=1</strong> but this is not always honored.</p>
<p>All of this does sound more complicated as message-passing
programming is definitely more complex than the multi-threaded approach.
But if you really need to apply more computing power to your job, it is
the only way to go.</p>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="scaling-study-of-the-distributed-memory-dot-product-code" class="callout-inner">
<h3 class="callout-title">Scaling Study of the Distributed-Memory Dot Product Code<a class="anchor" aria-label="anchor" href="#scaling-study-of-the-distributed-memory-dot-product-code"></a>
</h3>
<div class="callout-content">
<div class="tabs">
<nav><div id="nav-tab-3" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-3-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Python" type="button" role="tab" aria-controls="nav-tabpanel-3-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-3-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-R" type="button" role="tab" aria-controls="nav-tabpanel-3-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-C" type="button" role="tab" aria-controls="nav-tabpanel-3-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-3-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-3-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-3-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-3-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-3-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-3" class="tab-content">
<div id="nav-tabpanel-3-Python" class="tab-pane show active" aria-labelledby="nav-tab-3-Python" role="tabpanel">
<p>Measure the execution time for the dot_product_message_passing.py
code for 1, 4, 8, and 16 cores if you are on an HPC system with at least
2 compute nodes. You can try different combinations of nodes and cores
for each if you would like to see the effects of the network (for the 4
core test, try 2 nodes 2 cores vs 4 nodes 1 core).</p>
<p>If you want a more challenging exercise you can <strong>git
clone</strong> the Python matrix multiply code and test the scaling.</p>
</div>
<div id="nav-tabpanel-3-R" class="tab-pane" aria-labelledby="nav-tab-3-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-C" class="tab-pane" aria-labelledby="nav-tab-3-C" role="tabpanel">
<p>Not implemented yet.</p>
<p>If you want a more challenging exercise you can <strong>git
clone</strong> the C matrix multiply code and test the scaling.</p>
</div>
<div id="nav-tabpanel-3-Fortran" class="tab-pane" aria-labelledby="nav-tab-3-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-3-Matlab" class="tab-pane" aria-labelledby="nav-tab-3-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="tabs">
<nav><div id="nav-tab-4" class="nav nav-tabs" role="tablist">
<button class="nav-link active" id="nav-tab-4-Python" name="Python" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Python" type="button" role="tab" aria-controls="nav-tabpanel-4-Python" aria-selected="true">
  <h3 class="tab-header" id="nav-tab-heading-4-Python">
  Python
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-R" name="R" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-R" type="button" role="tab" aria-controls="nav-tabpanel-4-R" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-R">
  R
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-C" name="C" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-C" type="button" role="tab" aria-controls="nav-tabpanel-4-C" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-C">
  C
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Fortran" name="Fortran" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Fortran" type="button" role="tab" aria-controls="nav-tabpanel-4-Fortran" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Fortran">
  Fortran
  </h3>
</button>
<button class="nav-link" id="nav-tab-4-Matlab" name="Matlab" data-bs-toggle="tab" data-bs-target="#nav-tabpanel-4-Matlab" type="button" role="tab" aria-controls="nav-tabpanel-4-Matlab" aria-selected="false">
  <h3 class="tab-header" id="nav-tab-heading-4-Matlab">
  Matlab
  </h3>
</button>
</div>
</nav><div id="nav-tabContent-4" class="tab-content">
<div id="nav-tabpanel-4-Python" class="tab-pane show active" aria-labelledby="nav-tab-4-Python" role="tabpanel">
<p>In this code we initialize the vectors locally so there is no
communication involved. The only communication is the global sum at the
end, so we expect the scaling to be close to ideal. In my tests I
measured the single core run at 18.2 seconds, the 4 core run at 4.9
seconds for a 3.7 times speedup, the 8 core run at 2.3 seconds for a 7.9
times speedup, the 16 core run at 1.5 seconds for a 12 times speedup,
and the 32 core run at 0.73 seconds for a 25 times speedup. Theses are
all close to ideal which is great. The inefficiency in the
multi-threaded code comes from there being too little work in each loop
when the parallelization comes in the loop overhead, while for the
message-passing code there is no difference in the loop overhead, it’s
just the added global summation after the loop.</p>
</div>
<div id="nav-tabpanel-4-R" class="tab-pane" aria-labelledby="nav-tab-4-R" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-4-C" class="tab-pane" aria-labelledby="nav-tab-4-C" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-4-Fortran" class="tab-pane" aria-labelledby="nav-tab-4-Fortran" role="tabpanel">
<p>Not implemented yet.</p>
</div>
<div id="nav-tabpanel-4-Matlab" class="tab-pane" aria-labelledby="nav-tab-4-Matlab" role="tabpanel">
<p>Not implemented yet.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Distributed-memory computing is very flexible, extremely scalable,
but more difficult to program.</li>
<li>Understand key factors that can limit the efficient scaling of
message-passing programs.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://mpi4py.readthedocs.io/" class="external-link">mpi4py</a></li>
<li><a href="https://hpc-tutorials.llnl.gov/mpi/" class="external-link">LLNL MPI
tutorial</a></li>
<li><a href="https://www.mpich.org/documentation/guides/" class="external-link">MPICH user
guides</a></li>
<li><a href="https://www.open-mpi.org/doc/" class="external-link">OpenMPI function man
pages</a></li>
</ul>
</div>
</section></section><section id="aio-language-survey"><p>Content from <a href="language-survey.html">Language Survey</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/language-survey.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of each computer
language?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the criteria we will use to evaluate each language.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p>People choose a programming language for a given project for many
reasons. Sometimes they choose a language because it is the only one
they know, or because it is the only one their advisor knows. Many
languages are easier to learn and use, and some can be used
interactively.</p>
<p>In the next few sections, we want to do a survey of some of the more
common languages being used in science so that we can compare and
contrast each. When we first choose a language to use for a project, it
is common to only consider the capabilities of that language. For
example, R has great access to statistical analysis routines so it is a
great choice when those capabilities are needed. R and Python both can
be used interactively which appeals to many. But when we start talking
needing performance as well, then we have to balance the capabilities
that each language offers with the need to get great performance. This
performance can come in the form of scalar or single-core performance,
but also involves the ability to apply multiple cores or multiple
compute nodes.</p>
<p>Capability, ease of programming, performance, and parallelizability
are all attributes that we will need to consider. Capability refers to
the routines each language has access to like all the statistical
functions in R, the wide variety of artificial intelligence packages
programmed in Python, and the mathematical toolboxes in Matlab.
Usability means the ease of programming and the productivity of the
programmer. A low level language like C is incredibly flexible and
efficient but is more difficult to program and debug so that program
development takes longer. Performance is unimportant for simple
calculations but everything as we scale up to more complex and
computationally costly runs. This is why people may start a project in a
less efficient language and end up needing to switch languages when
performance begins to limit the science that can be done.
Parallelizability refers to how many compute cores we can apply to a
given job. This again ultimately limits the size of the science we can
achieve. We must understand how each language measures up for each of
these merits in order to choose an effective approach for each project
we are interested in.</p>
<ul>
<li>Capability - Access to the routines and data structures you
need</li>
<li>Usability - Ease of programming and productivity</li>
<li>Performance - How fast is the final code going to run?</li>
<li>Parallelizability - How many cores or compute nodes can be
used?</li>
</ul>
<p>Compute cycles on NERSC (National Energy Research Scientific
Computing) supercomputers are dominated by the compiled languages C/C++
and Fortran. Python is involved in one quarter of all jobs, but in a job
control role rather than a computational one. When you run jobs on large
$100 million supercomputers, you have to choose your language for
performance reasons even if that means putting extra effort into the
programming.</p>
<p>In a university environment it is very common to have less efficient
languages supported for computations such as Python, R, and Matlab. Even
though these are far from efficient computationally, they are typically
easier to program and can provide greater functionality. These factors
are often more important in cases where you may have a single programmer
writing a custom code for a particular project. So the choice of a
language can depend on the circumstances which may include factors like
how long an application is expected to be used versus how much effort it
will take to be developed.</p>
<p>It is useful to know a little bit about each language so you can
decide which is best for a given project or even which languages you
want to be proficient at for your career. The next sections will present
the strengths and weaknesses of many languages commonly used in
scientific computing. Some languages have common practices that are
performance bottlenecks that need to be avoided, so these will be
discussed and alternative approaches presented.</p>
<section><h2 class="section-heading" id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<hr class="half-width">
<ul>
<li><p>C/C++ and Python are row-major languages with arrays starting at
0.</p></li>
<li><p>Fortran, R, and Matlab are column-major languages with arrays
starting at 1.</p></li>
<li><p>C/C++ and Fortran are compiled languages for
high-performance.</p></li>
<li><p>Python, R, and Matlab have some optimized libraries to help with
performance.</p></li>
</ul>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Performance is just one criteria we need to understand when choosing
the best language for a given project.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-c-cpp"><p>Content from <a href="c-cpp.html">C and C++ Languages</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/c-cpp.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of programming in C and
C++?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of the C/C++ language.</li>
<li>Learn how to compile and run C/C++ programs.</li>
<li>Try compiling and running OpenMP and MPI versions.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="the-c-programming-language">The C Programming Language<a class="anchor" aria-label="anchor" href="#the-c-programming-language"></a>
<a class="anchor" aria-label="anchor" href="#the-c-programming-language"></a>
</h2>
<hr class="half-width">
<p>C is a very low level language that is extremely flexible and
efficient. It is the language used to program the Linux operating system
and the Python, Matlab, and much of the R languages. But all this power
comes at a price; it is more difficult to debug.</p>
<p>C files end in <strong>.c</strong> with header files ending in
<strong>.h</strong>. It is a row-major language meaning that a matrix is
stored by rows with elements of each row next to each other. Arrays are
numbered starting with zero same as with Python.</p>
<p>In C, variable types are less strict to allow for greater
flexibility, but this makes it more difficult for compilers to catch
errors before run time. Memory is dynamically allocated in a raw form
and assigned with a pointer to the first element, but there is little
control after that on how the programmer accesses the memory. If the
program tries to write to memory past what is allocated to that array,
there is no protection to prevent it from happening. So the programmer
is responsible for a lot more since the compiler cannot check much of
the code and provide detailed warnings. This is just the cost of the low
level access and flexibility of C.</p>
<p>Part of the power of C as well as C++ and Fortran is the access to
massive numbers of highly-optimized libraries of routines that have been
developed over the past 60 years. These involve scalar, vector, and
matrix algorithms in the BLAS (Basic Linear Algebra Subroutines)
libraries, sparse matrix libraries, Linear Algebra Package of LaPack and
its multi-processor version ScaLapack, FFT (Fast Fourier Analysis)
routines, and many others.</p>
<p><strong>OpenMP</strong> is the premier multi-threaded package
available for scientific computing. There are other methods of doing
multi-threaded computing like <strong>pThreads</strong> that are just as
efficient but harder to use. <strong>MPI</strong> is likewise developed
specifically for C/C++ and Fortran. While other languages have stripped
down versions implemented, none can rival the rich set of functionality
that the OpenMPI and MPICH packages provide with the full MPI
standard.</p>
<p>C doesn’t have as much access to statistical package that have been
developed for R, nor the mathematical toolboxes of Matlab and the wide
variety of artificial intelligence toolkits of Python. But it is
unrivaled in power, performance and flexibility.</p>
</section><section><h2 class="section-heading" id="the-c-language">The C++ Language<a class="anchor" aria-label="anchor" href="#the-c-language"></a>
<a class="anchor" aria-label="anchor" href="#the-c-language"></a>
</h2>
<hr class="half-width">
<p>C++ is a super set of C, meaning that it starts with C and adds
functionality beyond. Since C can be embedded with C++ code you get the
best of both worlds with access to the low level capabilities of C along
with the high level data structures and programming functionality of
C++. C++ files end with <strong>.cpp</strong> and use the same header
files ending in <strong>.h</strong>.</p>
<p>It is an object-oriented language, with objects having data that can
be private (hidden) or public (exposed) along with definitions of how
that object is created and interacts with other objects. This is good in
a sense since much of the work in creating an object is hidden from the
programmer, but hiding this process also means it is more difficult to
track memory usage and computations, both of which are very important in
understanding performance issues.</p>
<p>In C++ you also have overloaded operators, meaning that a
multiplication sign can have different meaning depending on the data
types it is applied to. If it is between 2 scalar variables then a
scalar multiplication is done, while the same operator between 2
matrices would do a matrix multiplication. This is why C++ is great for
programming other languages like R since the programmer can define what
each operator does and have that be dependent on the variable types
involved.</p>
<p>Much of what makes C++ so powerful is also what makes it more
difficult to work with where performance is concerned. The ability to
hide object initialization means that memory allocation is also hidden.
Operator overloading also can obscure the computations being done, as a
multiplication between two variables as in the example code below may
represent a single floating-point operation or a triply-nested loop if
the operands are both matrices. Memory and computations are simply less
explicit in C++ by design, and that can make it more difficult to
identify where performance issues may lie.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">CPP<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode cpp" tabindex="0"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>C <span class="op">=</span> A <span class="op">*</span> B<span class="op">;</span></span></code></pre>
</div>
</section><section><h2 class="section-heading" id="cc-compilers">C/C++ Compilers<a class="anchor" aria-label="anchor" href="#cc-compilers"></a>
<a class="anchor" aria-label="anchor" href="#cc-compilers"></a>
</h2>
<hr class="half-width">
<p>Unlike interpreted languages like Python, R, and Matlab, you have to
compile C and C++ code into an executable before running. The compiler
analyzes the code and optimizes it in ways that cannot be done on the
fly with interpreted languages making the resulting executable much more
efficient.</p>
<p>The most common compilers are the Gnu compiler <strong>gcc</strong>
with the C++ version <strong>g++</strong> and the exceptional commercial
Intel compilers <strong>icc</strong> and <strong>icpc</strong>. There
are many compiler options available but you can’t go wrong using
<strong>-g</strong> to generate a symbol table which will provide a line
number where the error occurred in case of a crash and
<strong>-O3</strong> for high-level optimization. You compile in the
OpenMP pragmas using <strong>-fopenmp</strong> for the Gnu compiles and
<strong>-openmp</strong> for the Intel compilers.</p>
</section><section><h2 class="section-heading" id="makefiles-for-compiling">Makefiles for compiling<a class="anchor" aria-label="anchor" href="#makefiles-for-compiling"></a>
<a class="anchor" aria-label="anchor" href="#makefiles-for-compiling"></a>
</h2>
<hr class="half-width">
<p>Compilation is actually done in two stages although for single file
applications it is typically done in one step. Source files get compiled
into binary object files with a <strong>.o</strong> suffix then all
those are linked together with any optimization libraries to produce the
executable.</p>
<p>Large applications may divide the source code into many smaller
source files for organizational reasons. A <strong>Makefile</strong> can
be developed that has all the logical directions to compile a single
application with a single <strong>make</strong> command. These
dependencies have many advantages, such as speeding up the compilation
process by allowing only those source files that have changed to be
recompiled into new object files. You will get a chance to examine a
small makefile in the exercise at the end of this lesson.</p>
</section><section><h2 class="section-heading" id="installing-large-software-packages">Installing large software packages<a class="anchor" aria-label="anchor" href="#installing-large-software-packages"></a>
<a class="anchor" aria-label="anchor" href="#installing-large-software-packages"></a>
</h2>
<hr class="half-width">
<p>To install any large software package you will need to read the
documentation and follow the directions. Having said that, many well
designed packages follow a similar approach of running a
<strong>configure</strong> script, then compiling the package with
<strong>make</strong> and installing it with <strong>make
install</strong>. The <strong>configure</strong> script usually requires
at least a <strong>–prefix=</strong> argument to tell it where to
install the software. While you will see many variations on this
approach it is good to at least understand this as a starting point.</p>
<ul>
<li>./configure –prefix=/path/to/installation/directory</li>
<li>make</li>
<li>make install</li>
</ul>
<div id="practice-compiling-and-running-c-codes" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="practice-compiling-and-running-c-codes" class="callout-inner">
<h3 class="callout-title">Practice compiling and running C codes<a class="anchor" aria-label="anchor" href="#practice-compiling-and-running-c-codes"></a>
</h3>
<div class="callout-content">
<p>The most common compiler for C is the Gnu C Compiler
<strong>gcc</strong>. This may be available by default on your system,
so try <strong>gcc –version</strong> to check. If not then you’ll need
to figure out how to gain access to it. You can also try the Intel C
Compiler <strong>icc</strong> if you have it available on your
system.</p>
<p>Try compiling the <strong>dot_product_c.c</strong> file using
<strong>gcc -g -O3 -o dot_product_c dot_product_c.c</strong> which tells
the compiler to use optimization level 3 and create the executable
dot_product_c from the source code dot_product_c.c. Once compiled you
can run this using <strong>./dot_product_c</strong> or submit a job to
the batch queue. Try also to compile with <strong>icc</strong> if it is
available.</p>
<p>Next try to compile the OpenMP multi-threaded version. You will need
to tell it to access the OpenMP library using a
<strong>-fopenmp</strong> flag for the <strong>gcc</strong> compiler or
<strong>-openmp</strong> for <strong>icc</strong>. Try a few runs with
different numbers of threads to get comfortable with running on multiple
cores.</p>
<p>If you have an MPI package installed, try compiling the
message-passing version using <strong>mpicc -g -O3 -o dot_product_c_mpi
dot_product_c_mpi.c</strong> and running some tests with <strong>mpirun
-np 4 dot_product_c_mpi</strong> for example.</p>
<p>If you want more practice you may try running the matmult_c.c code
and the optimized version matmult_cblas.c.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>On a modern Intel system the raw scalar code ran in 0.14 seconds as
did the single-threaded OpenMP and single-task MPI runs. The test on 4
threads took 0.06 seconds which is quite a bit off the 4x speedup we are
looking for. This again is due to how little work is being done during
each pass through the loop compared to the loop overhead. The MPI test
on 4 tasks is better at 0.047 seconds and is a little faster at 0.034
seconds on 8 tasks since the parallelization is done in a different
manner. How do your results compare to these?</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Learn about the characteristics of C/C++</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://www.guru99.com/c-programming-tutorial.html" class="external-link">C
Tutorial</a></li>
</ul>
</div>
</section></section><section id="aio-fortran"><p>Content from <a href="fortran.html">The Fortran Language</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/fortran.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of Fortran?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of Fortran.</li>
<li>Learn how to compile and run a Fortran program.</li>
<li>Identify source files for different versions of Fortran.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="modern-fortran">Modern Fortran<a class="anchor" aria-label="anchor" href="#modern-fortran"></a>
<a class="anchor" aria-label="anchor" href="#modern-fortran"></a>
</h2>
<hr class="half-width">
<p>Fortran is one of the oldest computer languages used for scientific
computing. One reason it is still heavily used is for historic reasons
since there are just so many lines of Fortran code out there that are
hard to replace. The good news is that this code base is extremely
efficient. The Fortran language has also continued to modernize adding
much of the same advanced functionality of C++.</p>
<p>Historically people used the f77 or Fortran 77 standard for a long
time (defined in 1977). Modern Fortran has made great strides from this
old standard in adding object oriented programming capabilities and a
less stringent form. Fortran code is identified by the
<strong>.f</strong> suffix or <strong>.F</strong> if there are
pre-processor commands embedded. You may also see the
<strong>.f90</strong> or <strong>.f95</strong> suffix to denote that the
code adheres to the fluid formatting of the Fortran 90 and 95 standard
defined in 1990 and 1995 respectively. Files with the
<strong>.mod</strong> suffix are modules.</p>
<p>All these newer standards have added capabilities similar to C++ like
dynamic memory allocation, object-oriented programming, and operator
overloading. More recent work has been geared toward adding more
parallel capabilities like the <strong>Coarray Fortran</strong> parallel
execution model and the <strong>Do concurrent</strong> construct for
identifying that a loop has no interdependencies and is therefore
capable of being parallelized.</p>
<p>The primary value of Fortran will always be its efficiency and the
same access to all the scientific and mathematical packages shared with
C/C++. It is a column-major language like R and Matlab, and starts
arrays at one instead of zero just like both of those as well. OpenMP
and MPI packages likewise have full support for Fortran.</p>
<p>So Fortran is every bit as powerful and efficient as C/C++, but it is
slowly being taken over by C/C++ on large supercomputers.</p>
<div class="section level3">
<h3 id="language-characteristics-to-avoid-gotchas">Language characteristics to avoid (gotchas)<a class="anchor" aria-label="anchor" href="#language-characteristics-to-avoid-gotchas"></a>
</h3>
<p>While most memory in C/C++ is dynamically allocated, it is very
common to have Fortran arrays statically allocated to a given size
especially in older codes. This memory comes from what internally is
called the <strong>stack</strong> which is a variable defined on each
system. In our cluster at Kansas State University the default stack size
as seen by doing <strong>ulimit -a</strong> is set to only a little over
8 MB while data arrays can easily exceed gigabyte sizes at times. When
you exceed the stack size, your job crashes with a segfault that will
not give you any useful information on what went wrong. If you think the
stack size may be an issue, you can include a command <strong>ulimit -s
unlimited</strong> before running your application to remove the stack
size limit entirely.</p>
</div>
<div class="section level3">
<h3 id="compiling-fortran-code">Compiling Fortran code<a class="anchor" aria-label="anchor" href="#compiling-fortran-code"></a>
</h3>
<p>Fortran is compiled with many of the same arguments and libraries
used for C/C++. The Gnu version is <strong>gfortran</strong> and the
Intel compiler is <strong>ifort</strong>. When using the OpenMP
multi-threading package you will add the <strong>-fopenmp</strong> or
<strong>-openmp</strong> flag respectively. To compile a Fortran MPI
code you will use <strong>mpifort</strong>.</p>
<p>While there are many compilation options for each of these, you can
general get by with <strong>-O3</strong> level 3 optimization. I also
strongly suggest always compiling with <strong>-g</strong>. This creates
a symbol table so that if your code crashes you at least get the line
number where it failed. Without this you get a pretty meaningless
onslaught of information that won’t really give you a clue as to the
problem. Compiling with <strong>-g</strong> should not slow down your
code as long as you also use <strong>-O3</strong>, and the extra size of
the executable should not matter.</p>
<p>Compiling source code to get an executable is again a two step
process where source code is compiled into binary object files which are
combined with any libraries needed in the linking stage. For simple
applications this may all be done in a single step. For more complex
codes involving many individual source files and modules it is common to
have a <strong>Makefile</strong> handle everything. The
<strong>Makefile</strong> provides the logic to compile only the parts
of an application code base that have changed, then link everything
together to produce the executable.</p>
<div id="practice-compiling-and-running-fortran-codes" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="practice-compiling-and-running-fortran-codes" class="callout-inner">
<h3 class="callout-title">Practice compiling and running Fortran codes<a class="anchor" aria-label="anchor" href="#practice-compiling-and-running-fortran-codes"></a>
</h3>
<div class="callout-content">
<p>Try compiling the <strong>dot_product_fortran.f90</strong> code with
the <strong>gfortran</strong> compiler, then try with
<strong>ifort</strong> if you have access to it. Do the same with the
optimized code <strong>dot_product_fortran_opt.f90</strong> to see the
difference that the built-in <strong>dot_product( x, y )</strong>
function can have. You can then compile the OpenMP version
<strong>dot_product_fortran_openmp.f90</strong> and do a scaling study,
and if you are on a system with MPI installed then try compiling and
running the MPI version <strong>dot_product_fortran_mpi.f90</strong>
using <strong>mpifort</strong>. Once you have compiled these codes
manually take a look at the <strong>Makefile</strong>. This contains all
the commands necessary to compile all the codes above with a single
command <strong>make all_fortran</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Each computer system may be set up differently with regard to what
compilers are available and how they need to be accessed. You may need
to contact your administrator for help if you are unsure whether you
have the Intel compiler suite installed, and how to access an MPI
package if available. In my tests on a modern Intel system the raw
Fortran code and optimized both took 0.14 seconds as did the OpenMP
using 1 thread and the MPI version using 1 task. OpenMP using 4 threads
took 0.063 seconds which is a little more than twice as fast and then
performance flattened out for more threads. The MPI version using 4
tasks took 0.05 seconds which is slightly better than the OpenMP
version, and 0.027 seconds for 8 tasks showing better scaling.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Learn about the characteristics of modern Fortran</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Fortran" class="external-link">Fortran
wiki</a></li>
<li><a href="https://fortran-lang.org/learn/" class="external-link">Fortran tutorials</a></li>
</ul>
</div>
</section></section><section id="aio-python"><p>Content from <a href="python.html">The Python Language</a></p>
<hr>
<p>Last updated on 2024-08-15 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/python.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of programming with
Python?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of programming in Python.</li>
<li>Learn how to work with virtual environments.</li>
<li>Learn about common performance-oriented libraries.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="python-performance">Python performance<a class="anchor" aria-label="anchor" href="#python-performance"></a>
</h3>
<p>Python is a high-level and extremely flexible language that has broad
acceptance within the high-performance computing community and even more
broadly with scientific and technical programmers. However, it isn’t a
performance language in the same manner as the compiled languages C/C++
and Fortran. It is an interpreted language that executes the code line
by line while compiled languages optimize larger blocks of code before
execution. At the Department of Energy supercomputing center NERSC
Python is involved in 25% of the code bases for the complex
applications, but only accounts for 4% of the CPU time on their systems.
This means that Python has a high level control role while the compiled
languages are used to do the performance computations.</p>
<p>A matrix multiplication algorithm implemented with raw Python code is
more than a hundred times slower than raw C code that is compiled. You
can achieve decent performance with Python only when your code uses the
highly-optimized libraries, and fortunately there is a rich set
available such as <strong>NumPy</strong> and <strong>SciPy</strong>
among many others. Even these can be slower than their compiled language
counterparts though, as a <strong>NumPy</strong> matrix multiplication
is still 50%-25% the speed depending on the matrix size compared to a
<strong>BLAS</strong> library <strong>DGEMM</strong> function available
for C/C++/Fortran.</p>
<p>While Python is not intended to be a performance language, there are
very good options available for parallelization. The
<strong>pymp</strong> library is a multi-threaded package based on a
stripped down version of the much more extensive <strong>OpenMP</strong>
library available for the compiled languages. <strong>pymp</strong> is
actively developed and maintained and provides the basic functionality
of OpenMP to the Python environment in an easy to use manner. The
<strong>mpi4py</strong> package likewise provides a stripped down MPI
environment for Python users. While neither of these is anywhere near as
complex nor complete as their compiled language cousins, both provide
the basics that most programmers will need.</p>
<p><strong>Dask</strong> is another option that extends Python in two
ways. If your data set is too large for the memory on one computer, it
provides the framework to use packages like <strong>NumPy</strong>,
<strong>Pandas</strong>, and Python iterators on data that is
distributed across multiple compute nodes in a cluster. It also provides
a dynamic task scheduler for parallelizing code.</p>
<p><strong>Numba</strong> is designed to speed up raw Python code by
compiling blocks of code programmed as functions that are tagged by the
programmer with <strong><span class="citation">@jit</span>(nopython=True,cache=True)</strong>. This
uses the industry standard <strong>LLVM</strong> compiler library, but
the compilation is not being done once ahead of the runtime as with
C/C++ and Fortran, it is being done at runtime in what is referred to as
a <strong>just-in-time</strong> or JIT manner. How effective this
approach can be will depend on how much the compilation can be done in
advance of when it is needed, and how much optimization it can do on the
fly, but there also is the option to save the compiled functions so that
they don’t need to be recompiled for subsequent runs. There are also
multi-threading options for parallelizing functions.</p>
<p><strong>Parsl</strong> is a parallelization library for Python that
very easily allows that programmer to define functions as separate apps
or applications that can be run on different cores or compute nodes.
This approach is especially useful in expressing multi-step workflows.
The link below provides more information on this approach.</p>
<p><a href="https://github.com/Parsl/parsl" class="external-link">Parsl python package
github</a></p>
<p><strong>memory_profiler</strong> is a Python package that allows easy
profiling of the memory usage of the code. If run externally using the
<strong>mprof</strong> command it reports the full memory usage of the
executable which can also be easily plotted. You can also add
<strong><span class="citation">@profile</span></strong> statements
before functions to provide line by line memory profiling to help
identify exactly where in your code your large memory allocations are
occurring. The link below provides a more detailed explanation with
examples.</p>
<p><a href="https://pypi.org/project/memory-profiler/" class="external-link">Python
memory-profiler package documentation</a></p>
<p>The <strong>line_profiler</strong> package in Python similarly can
run externally or internally, but provides timing information in a
line-by-line manner. Further information can be found at the link
below:</p>
<p><a href="https://github.com/pyutils/line_profiler" class="external-link">Python
line_profiler package github</a></p>
</div>
<div class="section level3">
<h3 id="python-capabilities">Python capabilities<a class="anchor" aria-label="anchor" href="#python-capabilities"></a>
</h3>
<p>For what Python lacks in raw performance as an interpreted language
it more than makes up for in its flexibility and easy of use. It is
common to develop code in an interactive environment like a Jupyter
Notebook which provides a very quick cycle from changing code to testing
it. It is a high level language that is easy to read, write, and learn,
and with advantages like dynamic variable typing. All this makes Python
a high productivity language enabling programmers to produce code more
quickly than in many lower level, more computationally efficient
languages.</p>
<p>Where this language really shines is in the extensive selection of
software packages that have been developed for the Python environment.
Some important examples are the TensorFlow and Scikit packages for doing
Artificial Intelligence and Machine Learning, but Python is commonly
used in fields as diverse as video processing, data mining, game and
language development, finance, and general programming.</p>
</div>
<div class="section level3">
<h3 id="technical-aspects">Technical aspects<a class="anchor" aria-label="anchor" href="#technical-aspects"></a>
</h3>
<p>Python is a row-major language like C/C++ where 2-dimensional arrays
or matrices are stored by row with elements in each row being next to
each other in memory. Python is also like C/C++ in that arrays are
numbered starting with 0. Languages like Fortran, R, and Matlab are the
opposite of Python and C in both these respects.</p>
<p>Python is an interpreted language like R and Matlab. It can be
compiled but not in the same way as C/C++ and Fortran where the compiler
optimizes whole blocks of code. The Python compiler simply packages the
code up so that it can run independent of Python or any installed
packages. This means the user running the ‘compiled’ python executable
does not need access to the same version of Python nor any virtual
environment with the python packages installed since everything is
packaged up in the executable. There will be an exercise at the end of
this section where you will be able to test this for yourself.</p>
</div>
<div class="section level3">
<h3 id="advantages-of-using-a-virtual-environment">Advantages of using a virtual environment<a class="anchor" aria-label="anchor" href="#advantages-of-using-a-virtual-environment"></a>
</h3>
<p>If you are on your own laptop or desktop computer you can install
Python packages system wide if you would like. On HPC systems there may
be some Python packages installed as loadable modules. You can also
install packages locally on your home directory using the
<strong>–user</strong> flag to <strong>pip install</strong>.</p>
<p>It is strongly advised however that you use a different virtual
environment for each new project. While you may need to re-install some
common packages like <strong>NumPy</strong>, having a clean virtual
environment for each project helps avoid problems with conflicting
versions of dependency packages. Quite often if users are having trouble
installing Python software, I’ll advise them to start with a clean
virtual environment and that fixes everything.</p>
<p>Creating a virtual environment is not very difficult. Below is an
example of creating one called <strong>env-py-3.7.4</strong> where I
labeled it after the version of Python being used. Once activated the
prompt will change to show that you are working in the
<strong>env-py-3.7.4</strong> environment. You can install any packages
you need, run your python code, then deactivate the environment when you
are done. The dollar sign is the command prompt to illustrate how the
prompt changes while the virtual environment is active.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">$</span> mkdir <span class="at">-p</span> ~/virtualenvs</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">$</span> cd ~/virtualenvs</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">$</span> python <span class="at">-m</span> venv <span class="at">--system-site-packages</span> python-hpc-user</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="ex">$</span> source ~/virtualenvs/python-hpc-user/bin/activate</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="kw">(</span><span class="ex">python-hpc-user$</span> pip install numpy scipy</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="kw">(</span><span class="ex">python-hpc-user</span><span class="kw">)</span><span class="ex">$</span> python python_code.py</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="kw">(</span><span class="ex">python-hpc-user</span><span class="kw">)</span><span class="ex">$</span> deactivate</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="ex">$</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="compiling-python">Compiling Python<a class="anchor" aria-label="anchor" href="#compiling-python"></a>
</h3>
<p>Compiling Python code does not do the same type of code loop analysis
that compiling C/C++ or Fortran does, so there really isn’t any speedup
involved. It does create a self-contained executable that no longer
needs to have a matching Python version or installed package virtual
environment available. It is therefore most useful when you are done
developing the code and want to distribute it as a binary.</p>
<p>Compiling Python code does vary depending on the operating system you
are on. In Linux you can compile code by adding a flag <strong>-m
py_compile</strong> which will create an executable in a
<strong><strong>pycache</strong></strong> directory.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> py_compile python_code.py</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">mv</span>  __pycache__/python_code.cpython-37.pyc  compiled_python_code.pyc</span></code></pre>
</div>
<p>The executable <strong>compiled_python_code.pyc</strong> will then
run on systems where Python is not installed and you have no virtual
environment activated.</p>
</div>
<div class="section level3">
<h3 id="language-characteristics-to-be-aware-of-gotchas">Language characteristics to be aware of (gotchas)<a class="anchor" aria-label="anchor" href="#language-characteristics-to-be-aware-of-gotchas"></a>
</h3>
<p>One of Python’s greatest strengths is that it is a simple high-level
language that is interpreted and easy to use. This is also its biggest
disadvantage when it comes to performance. Simply put, when you need
performance you need to use the highly-optimized numeric libraries.
Unfortunately compiling Python code really doesn’t help when there are
no optimized library codes available.</p>
<p>Virtual environments provide an excellent way to manage the
installation of software packages, and it is easy to use the <strong>pip
install</strong> command which installs the desired package and any
dependencies. You do always need to have the active virtual environment
match the Python version number used to install all those packages, so
if you want to use a newer version of Python you will have to reinstall
all the packages too.</p>
<p>Python2 was deprecated on January 1 of 2020. Everyone should be
programming in Python3 now, and these codes are not backwards compatible
with Python2. This means that if you encounter any Python2 code you
would either need to convert the code to Python3 or find an old and
deprecated version of Python2 and hope that still works. Basically if
you run into old python code at this point, expect to have some errors
to deal with.</p>
<p>Python uses a Global Interpreter Lock (GIL) to ensure that only one
thread can control the interpreter at any given time. This basically
defines Python as being single-threaded which simplifies everything
internally. The problem comes when a programmer wants to do
multi-threading to apply more power to solve a problem faster. The
<strong>pymp</strong> package gets around the GIL by forking off
separate processes and therefore each essentially has its own GIL. The
<strong>mpi4py</strong> package for message-passing is not affected
since with MPI each task is a separate copy of the same program. In
general, the GIL is something to be aware of but packages like
<strong>pymp</strong> have already done the work of getting around the
issue.</p>
<div id="play-with-the-python-dot-product-examples" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="play-with-the-python-dot-product-examples" class="callout-inner">
<h3 class="callout-title">Play with the Python dot product examples<a class="anchor" aria-label="anchor" href="#play-with-the-python-dot-product-examples"></a>
</h3>
<div class="callout-content">
<p>Take a look at the Python versions of the dot product code to see how
they differ from the C and Fortran versions. Also compare the
<strong>pymp</strong> multi-threaded and <strong>mpi4py</strong>
message-passing versions to the scalar version to see what changes were
made. If you haven’t already, run the scalar code and do scaling studies
with the multi-threaded and message-passing versions to see how they
compare with versions written in other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>While the syntax is different, the code is basically the same in each
language. Performance is much slower for raw Python code than the
compiled language. From looking at the same code in various languages,
which do you think would be easiest to write from scratch?</p>
</div>
</div>
</div>
</div>
<div id="compare-the-raw-matrix-multiply-code-to-a-numpy-version" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="compare-the-raw-matrix-multiply-code-to-a-numpy-version" class="callout-inner">
<h3 class="callout-title">Compare the raw matrix multiply code to a
<strong>NumPy</strong> version<a class="anchor" aria-label="anchor" href="#compare-the-raw-matrix-multiply-code-to-a-numpy-version"></a>
</h3>
<div class="callout-content">
<p>Do a scaling study of the <strong>matmult.py</strong> code for
various matrix sizes of 10, 100, and 1000. Compare this to the
<strong>matmult_numpy.py</strong> version to see how much of a
difference the highly-tuned library function makes.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>If you have already run the optimized C version, you may notice that
the compiled code still beats the optimized <strong>NumPy</strong>
routine by 2-4 times in my tests. Using the <strong>NumPy</strong>
routine closes the performance gap enormously but the C version is still
better.</p>
</div>
</div>
</div>
</div>
<div id="optional-exercise---try-compiling-a-python-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="optional-exercise---try-compiling-a-python-code" class="callout-inner">
<h3 class="callout-title">Optional Exercise - Try compiling a Python code<a class="anchor" aria-label="anchor" href="#optional-exercise---try-compiling-a-python-code"></a>
</h3>
<div class="callout-content">
<p>If you have time, try compiling one of the Python test codes supplied
like <strong>matmult_numpy.py</strong>. Then try running it without an
active virtual environment meaning that there is no
<strong>NumPy</strong> library installed.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Once compiled you should be able to run this with a command like:
<strong>./matmult.pyc 100</strong>.</p>
</div>
</div>
</div>
</div>
<div id="optional-exercise---try-implementing-memory-profiler-or-line_profiler" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="optional-exercise---try-implementing-memory-profiler-or-line_profiler" class="callout-inner">
<h3 class="callout-title">Optional Exercise - Try implementing memory-profiler or line_profiler<a class="anchor" aria-label="anchor" href="#optional-exercise---try-implementing-memory-profiler-or-line_profiler"></a>
</h3>
<div class="callout-content">
<p>If you have time, try implementing memory-profiler or line_profiler
in one of the Python test codes supplied like
<strong>matmult_numpy.py</strong>. Then try running the code to see the
memory or timing output.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div id="optional-homework---test-the-numba-version-of-the-dot-product-code" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="optional-homework---test-the-numba-version-of-the-dot-product-code" class="callout-inner">
<h3 class="callout-title">Optional Homework - Test the
<strong>Numba</strong> version of the dot product code<a class="anchor" aria-label="anchor" href="#optional-homework---test-the-numba-version-of-the-dot-product-code"></a>
</h3>
<div class="callout-content">
<p>Do a <strong>pip install numba</strong> then time the
<strong>dot_product_numba.py</strong> performance and compare to the raw
code. Does the performance change if you cache the compilation by adding
<strong>cache=True</strong>? You will need to run twice so that the
second time takes advantage of the cached compilation code.</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>Notice that in this code we needed to rewrite the computationally
intensive loops into functions. This does not take much effort but does
disrupt the program flow somewhat, but if it speeds up the runtime it is
usually worth it. Unfortunately in the case of the dot product the
<strong>Numba</strong> version takes 13 seconds compared to only 90
milliseconds for the raw code. Adding <strong>cache=True</strong> to
cache the compiled code does reduce the runtime down to 3.7 seconds but
this is still substantially worse than the original code. There are also
warnings about lists being deprecated as input arguments in the near
future. Switching our algorithm to use <strong>NumPy</strong> arrays may
be necessary but this also defeats the purpose of using
<strong>Numba</strong> since <strong>NumPy</strong> already has
optimized routines for the algorithms we are testing. So in short this
isn’t a really good test of the capabilities of <strong>Numba</strong>,
but is a good example of how these things don’t always work as hoped,
and it illustrates that <strong>Numba</strong> does not support all
aspects of Python. Forcing the computational parts of an algorithm into
functions is also detracts from the flow of any program, and is
definitely not what is considered as the Python way.</p>
</div>
</div>
</div>
</div>
<div id="optional-homework---write-a-pi-calculation-program-using-numba" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="optional-homework---write-a-pi-calculation-program-using-numba" class="callout-inner">
<h3 class="callout-title">Optional Homework - Write a Pi calculation
program using <strong>Numba</strong><a class="anchor" aria-label="anchor" href="#optional-homework---write-a-pi-calculation-program-using-numba"></a>
</h3>
<div class="callout-content">
<p>Write a Python version of the Pi calculation program and time raw
Python code versus <strong>Numba</strong> optimized. If you want to have
more fun try out <strong>Numba</strong> multi-threading compared to
<strong>pymp</strong> for this same algorithm. This is a much fairer
test of the capabilities of <strong>Numba</strong> since we are not
comparing it to optimized functions in <strong>NumPy</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution6" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution6" aria-expanded="false" aria-controls="collapseSolution6">
  <h4 class="accordion-header" id="headingSolution6"> Show me the solution </h4>
</button>
<div id="collapseSolution6" class="accordion-collapse collapse" aria-labelledby="headingSolution6" data-bs-parent="#accordionSolution6">
<div class="accordion-body">
<p>If you do this please contribute your code and timings.</p>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Learn about the characteristics of the Python language.</li>
<li>When performance is important always use optimized libraries!!!</li>
</ul>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://docs.python.org/3/tutorial/" class="external-link">Python
tutorial</a></li>
<li><a href="https://github.com/classner/pymp" class="external-link">pymp multi-threading
package</a></li>
<li><a href="https://github.com/mpi4py/mpi4py" class="external-link">mpi4py on github</a></li>
<li><a href="https://mpi4py.readthedocs.io/" class="external-link">mpi4py
documentations</a></li>
<li><a href="">TensorFlow</a></li>
<li><a href="">Scikit</a></li>
<li><a href="https://dask.org" class="external-link">Dask</a></li>
<li><a href="https://numba.pydata.org" class="external-link">Numba</a></li>
<li><a href="https://github.com/Parsl/parsl" class="external-link">Parsl python
package</a></li>
</ul>
</div></section><section id="aio-r"><p>Content from <a href="r.html">The R Language</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/r.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of the R programming
language?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Analyze the merits of the R Language.</li>
<li>Learn what to avoid in R when performance is important.</li>
<li>Learn a little about how to parallelize R code.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="programming-in-the-r-language">Programming in the R Language<a class="anchor" aria-label="anchor" href="#programming-in-the-r-language"></a>
<a class="anchor" aria-label="anchor" href="#programming-in-the-r-language"></a>
</h2>
<hr class="half-width">
<p>R is a high level programming language with an extremely rich set of
internal functions and add-on packages for statistical analysis and
other scientific programming. It is an interpretive language and
therefore the raw performance is not great. While there are ways to
write R code that performs better, it does take more work than in other
languages due to the many performance pitfalls inherent in the language,
and often you have to sift through the the many external packages to
find ones that work well for your needs. This section will try to
identify those pitfalls and present higher-performing alternatives.</p>
<p>R code is identified with the <strong>.R</strong> ending. External
add-on packages are installed into the user’s base directory under a
sub-directory also named <strong>R</strong>. These packages can be
easily installed from the <strong>CRAN</strong> mirrors using commands
like <strong>install.packages(“data.table”)</strong> then referenced in
the code with a similar statement like
<strong>library(data.table)</strong>. The wide range of scientific and
code packages available in R and their ease of installation and use are
its real strengths.</p>
<p>R programs can be run through the Linux command line interface (CLI),
submitted to batch queues, or run interactively from the CLI or the
popular graphical user interface Rstudio. The package Rshiny also makes
it easy to build interactive web applications from R.</p>
<p>R is like Python in that both are interpretive languages and both can
easily be used interactively which is helpful for minimizing the code
development cycle. The programmer is constantly changing the code and
immediately seeing the results. This strength in easing the development
cycle is also one source of its weaknesses in performance as
interpretive languages only execute a single line of code at a time
while compiled languages take whole blocks of code like the bodies of
loops and highly optimize them before execution time, but this is the
same trade-off that many languages face.</p>
<p>You can run R codes on multiple cores, but the parallel capabilities
of R are much more limited than the compiled languages C/C++ and Fortran
and even compared to Python. The basic parallel model for R is that
loops whether from <strong>lapply()</strong> or <strong>foreach</strong>
return an object that is either a list or a data frame with one entry
for the results from each pass through the loop. If your code uses the
loops in this manner then parallelizing them is relatively easy as you
just need to choose a back-end package to use, tell it how many cores
you want to use, then change the <strong>lapply()</strong> to an
<strong>mclapply()</strong> or the <strong>%do%</strong> in the
<strong>foreach</strong> to a <strong>%%dopar%</strong>.</p>
<p>However, it is very common in scientific codes to want to instead
have all parallel tasks operate on a shared-memory object like the
resulting matrix in our matrix multiplication example. People in the R
community often refer to back-end methods that use a
<strong>fork</strong> as shared-memory since the data structures can be
referenced in place in a shared manner as long as they are not written
to. This is quite different than what the HPC community refers to as
shared-memory, where all threads can write to a common data structure
and it is up to the programmer to ensure that threads don’t obstruct
each other.</p>
<p>Our matrix multiplication example illustrates this difference as the
source matrices A and B can be shared in R since they are read-only,
saving great time when a back-end that uses a virtual-memory fork is
used, but the elements of the result matrix C needs to be filled in by
each thread. In R this is very difficult while it is common place in the
compiled languages C/C++/Fortran as well as in Python. I have not found
any example code yet to do this in R though I have seen references that
it can be done with a <strong>bigmemory</strong> package and a lot of
jumping through hoops that goes well beyond the scope of this course.
There are also some methods of altering the default matrix
multiplication package used in the **%*%** operation but these are very
operating-system dependent.</p>
<p>There is extensive support for running C/C++/Fortran code across
multiple nodes using the message-passing interface MPI, and Python has a
stripped down version of this with the <strong>mpi4py</strong> package.
There is a package for R called Rmpi that provides wrappers around some
of the common MPI functions, but it was developed up until 2014 and
looks to have only been patched every year or two since then. Under
Windows you must compile with Microsoft MPI, and there are some
limitations in functionality. The doMPI back-end to
<strong>foreach</strong> runs on this Rmpi package, but it is not clear
that either work or work well due to the lack of current support so
neither can be recommended at this point.</p>
<p>There is a newer package called <strong>pdbMPI</strong> where the
<em>pbd</em> stands for Programming with Big Data. This is an interface
to the Message-Passing Initiative that is the foundation for distributed
parallel computing in the HPC community, and also is a dependency for
the <strong>pdbDMAT</strong> and <strong>kazaam</strong> packages for
working with matrices across multiple compute nodes. These packages are
much more recently developed and while still having 0.x version numbers
they are actively managed and being used on large supercomputer systems.
These provide true interfaces to MPI functions, not a back-end to
<strong>mclapply()</strong> or <strong>doParallel</strong>, so they are
more difficult to use but also much more powerful.</p>
</section><section><h2 class="section-heading" id="performance-pitfalls-in-r">Performance Pitfalls in R<a class="anchor" aria-label="anchor" href="#performance-pitfalls-in-r"></a>
<a class="anchor" aria-label="anchor" href="#performance-pitfalls-in-r"></a>
</h2>
<hr class="half-width">
<p>While all languages take effort to optimize and parallelize when
performance becomes important, with R it is often more about what
aspects of the language need to be avoided that are inhibiting
performance.</p>
<div class="section level3">
<h3 id="profiling-function">Profiling function<a class="anchor" aria-label="anchor" href="#profiling-function"></a>
</h3>
<p>As with most languages there are many methods that can be used to
time sections of code in order to understand where time is being spent.
For R the best options are to bracket the code of interest with calls
like <strong>t_start &lt;- proc.time()[[3]]</strong> and <strong>t_end
&lt;- proc.time()[[3]]</strong> then take the difference. The
<strong>proc.time()</strong> function will provide the best clock
available and the <strong>[[3]]</strong> part takes the elapsed or real
time that we want. The <strong>system.time()</strong> function can also
be used which returns the time taken to execute the function put in the
parentheses. This uses the same <strong>proc.time()</strong> clock but
may provide a more convenient method in some cases.</p>
<p>Another common approach that should be avoided is to use the
<strong>Sys.time()</strong> function. This similarly reports the time
between the bracketed code, but it by default auto-adjusts the units to
the length of the interval. So if your code takes 59 seconds it will
report 59, but if the same code takes 60 seconds it will auto-adjust to
minutes and report 1 instead. You can and always should manually specify
the units if you choose to use this function.</p>
</div>
<div class="section level3">
<h3 id="dataframes-and-the-rbind-function">Dataframes and the rbind() function<a class="anchor" aria-label="anchor" href="#dataframes-and-the-rbind-function"></a>
</h3>
<p>Dataframes are a very valuable and integral part of the R language.
The results from loops or functions are often returned in the form of
dataframes, and the input and output of data is built more on dumping
out whole dataframes to files than the line-by-line approaches that
other languages use. Dataframes in R are designed internally to be very
flexible to enable all of this, but this same design choice makes them
extremely inefficient from a computational view when working with larger
data sets.</p>
<p>The best example of this is the <strong>rbind()</strong> function
which is used to build a dataframe. It is very common to build a row of
data using <strong>cbind()</strong>then use <strong>rbind()</strong> to
add the row to the dataframe table, but internally R must allocate an
entirely new area of memory and copy all the existing data over as well
as the new data. This is because R is a column-major language so
elements in a column are stored next to each other. If R was row-major
then other alternatives would be present like having an array pointing
to each row in memory.</p>
<p>Having to recopy the entire dataframe each time a row is added is an
enormous performance penalty. I was approached with an R code and asked
to optimize and parallelize it since it was going to take a month of
runtime to complete. We generated a test case that took one hour, and
after commenting out only the <strong>rbind()</strong> function the
calculations took only 5 seconds. All the rest of the time was spent
copying the dataframe data to newly allocated memory each time a row was
added to the bottom.</p>
<p>If the code is building the dataframe just to dump it out to a file,
then one option is to simply print each row to file. R isn’t really
designed as well for this so it isn’t always optimal, but often is a
huge improvement over the <strong>rbind()</strong> inefficiency.</p>
<p>A better option is to use the <strong>data.table</strong> package
which is a drop in alternative to a dataframe. It is not as easy to use,
but is immensely more efficient than a dataframe since you can
pre-allocate the structure and insert values rather than having to
constantly rebuild the dataframe structure. There will be an exercise at
the end of this section that will allow you to see the difference in the
code and measure the performance of each approach.</p>
</div>
</section><section><h2 class="section-heading" id="parallelizing-r-code">Parallelizing R code<a class="anchor" aria-label="anchor" href="#parallelizing-r-code"></a>
<a class="anchor" aria-label="anchor" href="#parallelizing-r-code"></a>
</h2>
<hr class="half-width">
<p>As mentioned above, when a loop is parallelizable it is conceptually
fairly easy to accomplish this. The <strong>lapply()</strong> function
has a multi-core version <strong>mclapply()</strong> that spawns
multiple threads on a single compute node. The <strong>foreach</strong>
command can be parallelized by changing the <strong>%do%</strong> to
<strong>%dopar%</strong>. Both of these commands are part of the core
<strong>parallel</strong> library in R, but to make them work you need
to decide which of the many back-end library packages to use.</p>
<p>Considerations include whether you may need to run on Windows OS
which does not support the <strong>fork()</strong> function that is the
more efficient way to implement the needed functionality, whether you
may need to run a job across multiple compute nodes, and whether you
need to use shared-memory in your threads to enable working on a common
data set. Packages based on the <strong>fork()</strong> mechanism use
virtual memory rather than redundantly copying all data structures
needed. This can be enormously more efficient when dealing with large
data structures as each thread only gets a copy of the pages in memory
that it needs to alter. In our matrix multiplication example, that means
that the two matrices that only need to be read never get copied to each
thread, and the for matrix that is being calculated only the parts that
each thread is modifying get copied. For this reason it is always
recommended to use a back-end library based on <strong>fork()</strong>,
but Windows does not support this functionality so you may need to
consider other options that fully copy all data structures at the start
or even a socket-based cluster if you think your code might need to run
on Windows. Another option would be to install the Windows Subsystem for
Linux (WSL) which supports the <strong>fork)</strong> function.</p>
<p>The basic parallelization model for both approaches is the same, to
have each pass through the loop executed on different cores with one
line of data being returned for each iteration in the form of a list or
data frame. When the goal is to instead operate on a common data set
such as in our matrix multiplication example, then shared-memory is
needed. There are not very many back-end packages that support this
approach even though it is a very common need. In our matrix
multiplication example code we use the <strong>mcparallel</strong>
back-end and the <strong>bigmemory</strong> package. These are designed
to work on matrices, but would not work if you for example wanted all
threads to work on a different data structure like a shared-memory
data.table.</p>
<div class="section level3">
<h3 id="mclapply-pitfalls">mclapply() pitfalls<a class="anchor" aria-label="anchor" href="#mclapply-pitfalls"></a>
</h3>
<p>The <strong>mclapply()</strong> function is fairly straight forward
to use since you mostly need to supply the number of cores through the
<strong>mc.cores=</strong> argument. There are options to tune the way
the parallelization is done. The <strong>mc.preschedule=True</strong>
argument is the default, and this means that the number of iterations is
divided among the available cores at the start. This is highly
recommended since if this is turned off the system will fork a new
process for each iteration, do the work, then collapse that fork. This
can be incredibly inefficient since it means copying data structures
many times over so it should in general be avoided. If you do try this,
make sure to check the performance for both options as this choice can
drastically effect the efficiency of the resulting parallel
implementation.</p>
<div id="compare-raw-and-optimized-performance-of-matmult.r" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="compare-raw-and-optimized-performance-of-matmult.r" class="callout-inner">
<h3 class="callout-title">Compare raw and optimized performance of matmult.R<a class="anchor" aria-label="anchor" href="#compare-raw-and-optimized-performance-of-matmult.r"></a>
</h3>
<div class="callout-content">
<p>Run matmult_loops.R, matmult_foreach.R, and matmult_builtin.R for
matrix sizes 100 and 1000 to compare the performance of a raw loop to
the built-in matrix multiplication function. Also compare these numbers
to other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>I measured 500 seconds for the raw loop in R and 0.10 seconds for the
optimized built-in matrix multiplication function. Be aware that the
built-in function may use all the cores it has access to, so this may
not be a fair comparison unless you submit a batch scheduler job with
only 1 core allocated. Python for comparison took 300 seconds for raw
loops and 0.13 seconds for the <strong>numpy</strong> optimized routine,
but a larger run for size 10,000 had <strong>numpy</strong> at 46
seconds compared to <strong>R</strong> at 72 seconds. So in general, R
and Python are similar in speed for both raw and optimized code, but
Python is a little faster.</p>
</div>
</div>
</div>
</div>
<div id="test-the-scaling-of-the-rbind-function" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="test-the-scaling-of-the-rbind-function" class="callout-inner">
<h3 class="callout-title">Test the scaling of the rbind() function<a class="anchor" aria-label="anchor" href="#test-the-scaling-of-the-rbind-function"></a>
</h3>
<div class="callout-content">
<p>Profile the run time for using rbind() as the number of rows in the
data frame increases. Time runs of <strong>rbind.R</strong> for 10, 100,
1000, and 10000 rows.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>While rbind() is convenient and works well for small data frames, the
time to add rows begins to increase exponentially for data frames around
10,000 rows. I measured 1 second for 1000 rows, 48 seconds for 10,000
rows, and 5100 seconds for 100,000 rows. <strong>rbind()</strong> works
well for small data frames, but it is very inefficient when you scale up
to larger data sets of over 10,000 rows. This is because R copies the
entire data frame over each time it adds a new row.</p>
</div>
</div>
</div>
</div>
<div id="investigate-the-data-table-performance." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="investigate-the-data-table-performance." class="callout-inner">
<h3 class="callout-title">Investigate the data table performance.<a class="anchor" aria-label="anchor" href="#investigate-the-data-table-performance."></a>
</h3>
<div class="callout-content">
<p>Test the <strong>datatable.R</strong> code for 100, 1000, and 10000
rows and compare to the rbind() results.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>For 1,000 rows I measured 0.12 seconds for a data table set()
compared to 5.4 seconds for a data table assignment and 1.1 second for a
data frame rbind(). For 10,000 rows the performance really starts to
differ with 0.53 seconds for a data table set() compared to 50 seconds
for a data table assignment and 48 seconds for a data frame rbind(). For
a large test of 100,000 rows the data table set() still only took 5
seconds while the data table assignment took 485 seconds and the data
frame rbind() took 5100 seconds, or 1000x longer. This again shows that
while data frames can be convenient, when you scale up to larger sizes
you have to use data tables and the set() function.</p>
</div>
</div>
</div>
</div>
<div id="optional-homework---test-the-io-performance-in-r." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="optional-homework---test-the-io-performance-in-r." class="callout-inner">
<h3 class="callout-title">Optional Homework - Test the IO performance in R.<a class="anchor" aria-label="anchor" href="#optional-homework---test-the-io-performance-in-r."></a>
</h3>
<div class="callout-content">
<p>Test the <strong>fread.R</strong> code to see the speedup of the
<strong>fread()</strong> function from the optimized
<strong>data.table</strong> package compared to the standard
<strong>read.csv()</strong>. Time runs of <strong>fread.R</strong> for
10,000 rows, 100,000 rows, and 1,000,000 rows.</p>
</div>
</div>
</div>
<div id="accordionSolution4" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution4" aria-expanded="false" aria-controls="collapseSolution4">
  <h4 class="accordion-header" id="headingSolution4"> Show me the solution </h4>
</button>
<div id="collapseSolution4" class="accordion-collapse collapse" aria-labelledby="headingSolution4" data-bs-parent="#accordionSolution4">
<div class="accordion-body">
<p>For 10,000 rows I saw similar results for each function, but for
100,000 rows <strong>fread()</strong> was 10 times faster than
<strong>read.csv()</strong> and for 1,000,000 rows it was 100 times
faster. This is another example illustrating when to avoid the core R
functionality and use the external add-on packages to achieve
performance in your code.</p>
</div>
</div>
</div>
</div>
<div id="advanced-homework---use-the-pdbmpi-package-to-code-and-run-a-parallel-hello-world-program" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="advanced-homework---use-the-pdbmpi-package-to-code-and-run-a-parallel-hello-world-program" class="callout-inner">
<h3 class="callout-title">Advanced Homework - Use the
<strong>pdbMPI</strong> package to code and run a parallel Hello World
program<a class="anchor" aria-label="anchor" href="#advanced-homework---use-the-pdbmpi-package-to-code-and-run-a-parallel-hello-world-program"></a>
</h3>
<div class="callout-content">
<p>For those who want a challenge, follow the <strong>pdbMPI</strong>
link at the end of this lesson an write, run, and test the Hello World
program.</p>
</div>
</div>
</div>
<div id="accordionSolution5" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution5" aria-expanded="false" aria-controls="collapseSolution5">
  <h4 class="accordion-header" id="headingSolution5"> Show me the solution </h4>
</button>
<div id="collapseSolution5" class="accordion-collapse collapse" aria-labelledby="headingSolution5" data-bs-parent="#accordionSolution5">
<div class="accordion-body">
<p>I would love to have a pdbMPI-based matrix multiply code available
for people to look at and test if anyone finds one.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>R is a very powerful language because of the enormous set of
statistical and external scientific libraries that have been developed
for it. It can however be difficult to program in since much effort
involves programming in supplemental packages rather than the core
language. Users need to therefore know not only the core R language, but
be familiar with which external programming packages to use when more
performance or flexibility is needed, and this can be an ever changing
target.</p>
<p>It is often very challenging to get good performance out of R code.
Elements of the core language like dataframes have inherent performance
and scaling problems. Parallelization seems as easy as registering the
desired number of cores and changing the <strong>%do%</strong> in a
<strong>foreach</strong> loop to <strong>%dopar%</strong>, but setting
up writable shared-memory is difficult to impossible. Each back-end
package has different capabilities and efficiencies so it can be
difficult to decide which approach is best. While it is possible to
achieve good performance with R code, much of the work involves
programming around the built-in capabilities using optimized add-on
libraries, and you have to understand which of the many packages to
utilize. It is hoped that this section can at least steer people in the
correct direction with some of these performance oriented issues.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Learn about the characteristics of the R language.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://www.r-project.org/other-docs.html" class="external-link">R
documentation</a></li>
<li><a href="https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html" class="external-link">Foreach
function</a></li>
<li><a href="https://www.rdocumentation.org/packages/parallel/versions/3.4.0/topics/mclapply" class="external-link">mclapply
function</a></li>
<li><a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html" class="external-link">data.table
package</a></li>
<li><a href="https://github.com/snoweye/pbdMPI" class="external-link">Programming with Big
Data - MPI package</a></li>
<li><a href="https://github.com/RBigData/pbdDMAT" class="external-link">pdbDMAT
package</a></li>
<li><a href="https://www.rstudio.com" class="external-link">Rstudio</a></li>
<li><a href="https://shiny.rstudio.com" class="external-link">Rshiny</a></li>
</ul>
</div>
</section></section><section id="aio-matlab"><p>Content from <a href="matlab.html">The Matlab Language</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/matlab.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the strengths and weaknesses of the Matlab language?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the performance and parallelization characteristics of
Matlab.</li>
<li>Learn the practicality of using the Matlab compiler on HPC
systems.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="programming-in-the-matlab-language">Programming in the Matlab Language<a class="anchor" aria-label="anchor" href="#programming-in-the-matlab-language"></a>
<a class="anchor" aria-label="anchor" href="#programming-in-the-matlab-language"></a>
</h2>
<hr class="half-width">
<p>Matlab is a commercial programming language designed for broad use in
science and mathematics. The obvious drawback of it being commercial
software is that it costs money and has licensing restrictions when you
use it. The more positive aspect is that it is professionally developed
and maintained with lots of advanced science modules.</p>
<p>The core Matlab code is interpreted which limits its speed but there
are lots of highly optimized and parallelized low level operations that
often lead to very good performance. Users can also parallelize code
manually using <strong>parfor</strong> loops which are easy to implement
but difficult to make efficient. Many modules are also programmed to run
on NVIDIA GPUs for acceleration.</p>
<p>There is a free language <strong>GNU Octave</strong> that runs much
of raw Matlab code. Some of the more advanced features are not
supported, but some like parallelization simply have a different format.
Octave also has lots of user-contributed modules covering a broad range
of science and mathematics.</p>
<div class="section level3">
<h3 id="matlab-toolboxes">Matlab Toolboxes<a class="anchor" aria-label="anchor" href="#matlab-toolboxes"></a>
</h3>
<p>The Matlab core can be enhanced with a very wide variety of add-on
toolboxes. Some are more generic while others are very specific to
certain areas of science. Some of the more common ones include:</p>
<ul>
<li>Parallel Computing Toolbox</li>
<li>Simulink - Simulation and Model-Based Design</li>
<li>Statistics and Machine Learning</li>
<li>Curve Fitting</li>
<li>Control Systems</li>
<li>Signal Processing</li>
<li>Mapping</li>
<li>System Identification</li>
<li>Deep Learning</li>
<li>DSP System</li>
<li>Datafeed</li>
<li>Financial</li>
<li>Image Processing</li>
<li>Text Analytics</li>
<li>Predictive Maintenance</li>
</ul>
<p>There are many domain-specific toolboxes that include Bioinformatics,
Aerospace, Wavelets, and Econometrics to name a few.</p>
</div>
<div class="section level3">
<h3 id="commercial-licensing-restrictions-and-costs">Commercial licensing restrictions and costs<a class="anchor" aria-label="anchor" href="#commercial-licensing-restrictions-and-costs"></a>
</h3>
<p>Matlab has a base cost with toolboxes being extra. There are annual
and perpetual licenses with all pricing being in U.S. dollars.</p>
<p><a href="https://www.mathworks.com/pricing-licensing.html?prodcode=ML&amp;intendeduse=student" class="external-link">click
here for pricing</a></p>
<p>There are huge educational discounts with students paying under a
hundred U.S. dollars for Matlab, Simulink, and 10 add-on toolboxes.
Teachers and researchers also get large discounts, but add-on toolboxes
can increase the cost quickly as the more common ones can run a few
hundred dollars and more specialized toolboxes even more.</p>
<p>Licenses for HPC clusters can be floating meaning that each license
can be checked out by an authorized user and used on a given number of
processors or nodes. This does require a license server to be set up
which can be done on the HPC cluster or handled remotely. Just be aware
that with commercial software there is additional setup required as well
as costs.</p>
</div>
<div class="section level3">
<h3 id="using-the-matlab-compiler">Using the Matlab compiler<a class="anchor" aria-label="anchor" href="#using-the-matlab-compiler"></a>
</h3>
<p>When we talk about compiling for C/C++ and Fortran, we are talking
about analyzing a block of code like the body of a loop to optimize the
code so that it runs faster. Matlab and Python both have compilers but
neither does this. In both cases the compiler packages up the code,
interpreter, and libraries into an executable that can be run
independently. The compiled code therefore does not run any faster.</p>
<p>A programmer will always start by developing and running their code
in raw form which requires checking out a Matlab license. If you need to
share your Matlab code with others who do not have access to a Matlab
license, then you would want to compile the code to package it into an
executable that doesn’t need Matlab to run. In an HPC cluster context,
you still want to develop your code in raw Matlab but when it is time to
run you want to again compile it into an executable so that many copies
can be run without needing a separate Matlab license for each. In this
way, an HPC center only needs as many Matlab licenses as they want to
have simultaneous users developing code rather than needing to support
the number of jobs run.</p>
<div class="section level4">
<h4 id="minor-compiler-mcc-gotcha">Minor compiler mcc gotcha<a class="anchor" aria-label="anchor" href="#minor-compiler-mcc-gotcha"></a>
</h4>
<p>When you run the Matlab compiler, it does check the license out for a
half hour at a time so if you just have a single license for a cluster
users may end up waiting a bit for access.</p>
</div>
</div>
<div class="section level3">
<h3 id="performance">Performance<a class="anchor" aria-label="anchor" href="#performance"></a>
</h3>
<p>Matlab is not a compiled language so raw code is much slower than
C/C++/Fortran. It is however faster than Python and R as shown in the
serial matrix multiply of 1000x1000 matrices taking 5 seconds compared
to Python at 306 seconds. The built-in routines that are optimized and
parallelized are going to be similar in the different languages, and in
this case Matlab takes 0.7 seconds while the Numpy version in Python
takes 0.13 seconds in the same test.</p>
<p>Matlab does have very strong integration with optimized and
parallelized library routines throughout its modules which brings
automatic efficiency and parallelization when available.</p>
</div>
</section><section><h2 class="section-heading" id="parallelization-methods">Parallelization methods<a class="anchor" aria-label="anchor" href="#parallelization-methods"></a>
<a class="anchor" aria-label="anchor" href="#parallelization-methods"></a>
</h2>
<hr class="half-width">
<p>The <strong>Parallel Computing Toolbox</strong> is the source of most
of the parallel computing capabilities in Matlab. It provides the
ability to program using multiple cores, multiple nodes, and GPUs
without explicitly using CUDA or MPI. Matlab also includes a wide
variety of parallelized numerical libraries at its core to automatically
take advantage of the hardware you allocate to your job. The
<strong>Simulink</strong> toolkit allows the user to set up and run
multiple simulations of a model in parallel. The <strong>Matlab Parallel
Server</strong> can also be used to run matrix calculations that are too
large to fit in the memory of a single computer.</p>
<div class="section level3">
<h3 id="parallelizing-loops-with-parfor">Parallelizing loops with <strong>parfor</strong>
<a class="anchor" aria-label="anchor" href="#parallelizing-loops-with-parfor"></a>
</h3>
<p>When iterations of a <strong>for</strong> loop do not depend on each
other, the iterations can be spread across multiple processes within the
same compute node in a distributed-memory manner, multiple threads in a
shared-memory approach, or they can be spread across multiple nodes. All
3 approaches are accomplished by changing the <strong>for</strong> loop
to a <strong>parfor</strong> loop. Computations will be split across
multiple cores whether they are on the same compute node or multiple
nodes. This provides a very easy means of parallelizing code and the
flexibility of running the same code in a variety of parallel
environments.</p>
<p>This flexibility comes with a prices though. Distributed-memory
approaches are often only efficient when the flow of data between
processes is careful controlled which is not possible here. It often
requires much more work to get the needed efficiency out of complex
algorithms. This type of automatic distributed-memory approach also
results in large data sets being redundantly copied to all processes
which can lead to extra execution time for the communications and much
extra memory usage. So if you are working with a 1 GB size matrix and
want to run on a 128 core AMD system you would have to copy and
redundantly store 128 GB of data at the start.</p>
<p>The multi-threaded approach is designed to avoid this redundant
memory use by leaving read-only data sets in place rather than copying
them to each thread. This holds much greater promise conceptually, but
tests with a simple parallel matrix multiplication are showing much
slower times than expected. Even a parallel dot product which is
trivially parallel takes longer than the serial version so it is unclear
how useful even the multi-threaded <strong>parfor</strong> is in
general.</p>
<p>So while Matlab provides an easy-to-use and flexible parallel
programming environment with <strong>parfor</strong>, it can suffer
greatly when dealing with large data sets and complex algorithms, and
doesn’t even do all that well on simple algorithms. From these tests so
far I would recommend using this approach mostly for trivially parallel
algorithms and smaller data sets and testing very carefully.</p>
<p><strong>NOTE: Loop iterations are non-deterministic and indices must
be consecutive increasing integers, and there is no nesting of loops
allowed.</strong></p>
</div>
</section><section><h2 class="section-heading" id="octave">Octave<a class="anchor" aria-label="anchor" href="#octave"></a>
<a class="anchor" aria-label="anchor" href="#octave"></a>
</h2>
<hr class="half-width">
<p>GNU Octave is a language that is largely compatible with Matlab, but
it is free and unlicensed. It can be used to run many Matlab programs
using <strong>octave &lt; matlab_code.m</strong> though many advanced
features of Matlab may not be supported. There are many add-on packages
available for Octave but these are different from those available for
Matlab.</p>
<p>There is a <strong>parallel</strong> toolbox that is well developed.
This provides a local parallel execution environment similar to the
single-node multi-process capability of <strong>parpool</strong>. There
are also tools to work with clusters of computers, but these are more
similar to message-passing commands where you manually send and receive
data to and from remote processes and manually initiate function
evaluation.</p>
<div id="test-the-performance-of-the-matlab-matrix-multiplication-code." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="test-the-performance-of-the-matlab-matrix-multiplication-code." class="callout-inner">
<h3 class="callout-title">Test the performance of the Matlab matrix multiplication code.<a class="anchor" aria-label="anchor" href="#test-the-performance-of-the-matlab-matrix-multiplication-code."></a>
</h3>
<div class="callout-content">
<p>If you have access to a Matlab license or Octave, test the
performance of the <strong>matmult.m</strong> code for a matrix size of
1000 and compare to other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>For the 1000x1000 matrices, I measure 5 seconds for the serial code,
0.7 seconds for the built-in matrix multiply that uses low level
optimized BLAS routines. The parpool multi-process test takes 530
seconds which is understandably slow since it is doing the matrix
multiplication in a distributed memory manner without explicitly
programming it to do this efficiently. The multi-threaded parpool test
measured in at &gt; 510 seconds which is very disappointing since there
should be no copying of the matrices at the beginning. It isn’t clear
what is happening behind the scenes for this to be so slow.</p>
</div>
</div>
</div>
</div>
<div id="test-the-performance-of-the-matlab-dot-product-code." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="test-the-performance-of-the-matlab-dot-product-code." class="callout-inner">
<h3 class="callout-title">Test the performance of the Matlab dot product code.<a class="anchor" aria-label="anchor" href="#test-the-performance-of-the-matlab-dot-product-code."></a>
</h3>
<div class="callout-content">
<p>Test the performance of the <strong>dot_product.m</strong> code for
an array size of 100,000,000 and compare to other languages.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>I measure serial performance at 0.5 seconds with the built in
optimized routine at 0.2 seconds on 8 cores for a modest speedup. The
multi-core <strong>parfor</strong> loop on the same 8 cores takes 2.1
seconds while the multi-threaded <strong>parfor</strong> loop takes a
disappointing 0.9 seconds which is still greater than the serial code.
The overhead for using these methods is still much larger than the
performance gain which indicates the parfor method should only really be
used for very coarse grained algorithms.</p>
</div>
</div>
</div>
</div>
<div id="optional-homework-alter-the-matmult.m-code-to-run-on-multiple-nodes-and-multiple-cores." class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="optional-homework-alter-the-matmult.m-code-to-run-on-multiple-nodes-and-multiple-cores." class="callout-inner">
<h3 class="callout-title">Optional Homework: Alter the
<strong>matmult.m</strong> code to run on multiple nodes and multiple
cores.<a class="anchor" aria-label="anchor" href="#optional-homework-alter-the-matmult.m-code-to-run-on-multiple-nodes-and-multiple-cores."></a>
</h3>
<div class="callout-content">
<p>Test on multiple compute nodes and compare performance to the serial
and multi-threaded versions. If you want a real challenge try setting
the code up to run on a cloud server. And an even bigger challenge would
be to convert matmult.m to run on Octave’s parallel computing
environments.</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>If you do develop code for this, let us know so we can consider
including your work for others to see.</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>The greatest value of Matlab is the very wide range of professionally
developed and maintained packages that are available in many areas of
science. This comes at a financial cost that often limits how codes can
be used, but some of this can be alleviated in an HPC environment by
using the Matlab <strong>mcc</strong> compiler to create an executable
that does not need a license to run on many compute nodes at once.</p>
<p>Matlab code itself is not that fast, but it uses highly-optimized
library routines seamlessly whenever possible. Adding parallelism into a
code manually is often as easy as changing the <strong>for</strong> loop
to a <strong>parfor</strong> loop, but flexibility and ease of use often
do not produce efficient code. These methods are probably only useful
for trivially parallel algorithms.</p>
<p>Octave is a viable option to avoid the cost of Matlab, and has many
add-on packages of its own as well as parallel computing capabilities.
You should however only expect the more basic Matlab codes to run with
Octave, then you would need to choose to split off into the Octave world
itself.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Learn about the characteristics of the Matlab language.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://www.mathworks.com/" class="external-link">Matlab documentation</a></li>
<li><a href="https://octave.org/" class="external-link">Octave website</a></li>
<li><a href="https://www.mathworks.com/products/parallel-computing.html" class="external-link">Matlab
Parallel Computing Toolbox</a></li>
<li><a href="https://www.mathworks.com/products/simulink.html" class="external-link">Matlab
Simulink</a></li>
<li><a href="https://www.mathworks.com/help/thingspeak/matlab-toolbox-access.html" class="external-link">Matlab
Toolboxes and Examples</a></li>
</ul>
</div>
</section></section><section id="aio-array-jobs"><p>Content from <a href="array-jobs.html">Array Jobs</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/array-jobs.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What do array jobs have to do with high-performance computing?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn what an array job is in a batch scheduler.</li>
<li>Understand what types of science can make use of array jobs.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="array-jobs-using-slurm">Array jobs using Slurm<a class="anchor" aria-label="anchor" href="#array-jobs-using-slurm"></a>
</h3>
<p>An array job is mostly just like a normal job script in that it has
arguments at the top prefaced with <strong>#SBATCH</strong> that tell
the scheduler what resources are being requested followed by a list of
commands to be executed at run time. The difference is that array jobs
have an extra allocation request line like <strong>#SBATCH
–array=1-5</strong> that tells the Slurm scheduler to launch in this
case 5 individual jobs identical in every way except that each will have
a different value for the environmental variable
<strong>$SLURM_ARRAY_TASK_ID</strong>. This variable can be used to make
each run unique as part of a series of related runs. It might be used as
an input argument to the code being run in order to let the application
determine what is different with each run. It may also be used to choose
a different input file from a list to use when running the application.
This is very flexible and is entirely up to the programmer to decide how
to use it.</p>
<p>For the job below the <strong>$SLURM_ARRAY_TASK_ID</strong> variable
will be set to 1, 3, or 5. since the script specifies that the task ID
starts at 1, ends at 5, and steps by 2.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">#!/bin/bash -l</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">#SBATCH --job-name=array_test</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co">#SBATCH --time=0-0:1:00</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co">#SBATCH --nodes=1</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#SBATCH --ntasks-per-node=1</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#SBATCH --mem=1G</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#SBATCH --array=1-5:2</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="fu">hostname</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"Hello from array task ID </span><span class="va">$SLURM_ARRAY_TASK_ID</span><span class="st">"</span></span></code></pre>
</div>
<div id="submit-an-array-job" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="submit-an-array-job" class="callout-inner">
<h3 class="callout-title">Submit an array job<a class="anchor" aria-label="anchor" href="#submit-an-array-job"></a>
</h3>
<div class="callout-content">
<p>If you have access to an HPC system with Slurm installed, submit the
<strong>sb.array_test</strong> script from the <strong>scripts</strong>
sub-directory using <strong>sbatch sb.array_test</strong> then look at
the output. If your HPC system has a different scheduler you may need to
figure out how to submit an array job yourself and will need to write
the job script from scratch. If you want more of a challenge you can try
writing a script to choose an input filename from a list using
<strong>$SLURM_ARRAY_TASK_ID</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>This will run 3 individual jobs that will show the
<strong>$SLURM_ARRAY_TASK_ID</strong> to be 1, 3, or 5.</p>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="array-jobs-as-parallel-computing">Array jobs as parallel computing<a class="anchor" aria-label="anchor" href="#array-jobs-as-parallel-computing"></a>
</h3>
<p>Most of the time when we thing of parallel computing we think of
taking a single program and making it run faster by applying more
compute power to it in terms of more compute cores. Array jobs allow us
to do the same thing, but in this case we are running many individual
programs instead of just one.</p>
<p>One common area of science where we can make use of this is to do
what is called a parameter sweep. You may have a set of parameters such
as system temperature, pressure, atom type, and lattice type (atomic
arrangement) where you need to run the same code on all these different
input parameters. Array jobs allow you to do parameter sweeps like this
in a very convenient manner with a single job script. This makes it easy
to submit and manage.</p>
<p>Another common use is in doing statistical science. For applications
that use a random number sequence, you may want to run the same
simulation many times using a different seed to determine how the
results vary statistically as the random number sequence changes.</p>
</div>
<div class="section level3">
<h3 id="programming-habits-to-avoid">Programming habits to avoid<a class="anchor" aria-label="anchor" href="#programming-habits-to-avoid"></a>
</h3>
<p>Many programmers write scripts to submit lots of individual jobs
instead of making use of the array jobs functionality. While the result
is basically the same, this method should be avoided in general. Lots of
individual jobs can clog up the queue making it difficult for users to
see where other jobs are, and can also affect scheduling since batch
systems have limits on how deep they can look. Array jobs avoid both of
these issues and make it much easier to manage the resulting jobs since
canceling your array job is for instance just the same as canceling an
individual job.</p>
<p>The testing cycle is always more important when you are dealing with
large numbers of jobs. One user submitted an array job for tens of
thousands of tasks that had a typo in the email address so when it ran
it spammed the ticket system with tens of thousands of bounced emails.
Always start by running a few typical jobs to nail down your resource
requests. Running a test job with just a few array IDs will allow you to
ensure that each job is using the <strong>$SLURM_ARRAY_TASK_ID</strong>
in the desired manner. Then when you are confident that your script is
working as intended you are ready to submit the full array job.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Array jobs provide an easy way submit and manage large numbers of
similar jobs.</li>
<li>Array jobs are another way to do parallel computing, but by running
lots of small jobs individually.</li>
<li>Test your script carefully on a few array IDs before submitting the
full job.</li>
</ul>
</div>
</div>
</div>
</div></section><section id="aio-gpus"><p>Content from <a href="gpus.html">Accelerating Scientific Computing with GPUs</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/gpus.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What differences are there in handling applications that can use a
GPU?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn a little about how GPUs can accelerate some scientific
codes.</li>
<li>Understand the basics of compiling and running GPU codes.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="how-to-use-a-gpu-to-accelerate-scientific-calculations">How to use a GPU to Accelerate Scientific Calculations?<a class="anchor" aria-label="anchor" href="#how-to-use-a-gpu-to-accelerate-scientific-calculations"></a>
<a class="anchor" aria-label="anchor" href="#how-to-use-a-gpu-to-accelerate-scientific-calculations"></a>
</h2>
<hr class="half-width">
<p>We normally think of a Graphics Processing Unit or GPU in terms of
displaying graphics to a computer monitor. GPU cards are designed with
many streaming processors that are great at performing lots of similar
computations. While this makes them ideal for doing graphics work, it
also makes them good for running some scientific codes. GPU cards can
accelerate some scientific codes by an order of magnitude while costing
much less than what the equivalent CPUs would.</p>
<p>NVIDIA dominates the GPU accelerating market with both 32-bit or
consumer grade GPUs like the NVIDIA RTX 4090 that can cost around $1500,
but they also produce 64-bit Tesla cards that have no graphics ports at
all and are only designed for scientific computing. These include the
NVIDIA A100 which can cost as much as $11,000 each or their newest H100
that can cost twice that. Compute nodes can host 1-8 GPU cards each and
in some systems the high-end A100s and H100s may be linked together
through a fast NVLink connection. Otherwise a multi-GPU run would need
to communication across the PCI bus.</p>
<p>AMD GPUs can also be used to accelerate scientific jobs and are
increasingly being found in the fastest supercomputers in the world. The
code development is still behind that of the NVIDIA CUDA community due
to its much later entrance into the scientific computing market. AMD has
a <strong>Hip</strong> compiler that is used to generate code for the
AMD GPUs, and it has the benefit of being able to compile the same code
for NVIDIA GPUs as well. The AMD GPU line includes 32-bit GPUs such as
the Radeon RX 6000 series and the 64-bit Radeon Instinct MI100 cards
with costs comparable to the NVIDIA line.</p>
<div class="section level3">
<h3 id="using-gpus-for-machine-learning">Using GPUs for Machine Learning<a class="anchor" aria-label="anchor" href="#using-gpus-for-machine-learning"></a>
</h3>
<p>Artificial Intelligence applications like Machine Learning can be
done on any CPU or GPU. However, GPUs with tensor units can do them
faster and less costly since tensor units can do more operations per
clock cycle, and the lower precision of the results do not matter for
Machine Learning applications. If your system is going to be primarily
used for Machine Learning, you’ll want to look at the tensor units in
the GPUs while the memory will limit the size of the system you can work
with.</p>
<p>AMD and Intel GPUs do not have tensor units. NVIDIA offers tensor
units in their 32-bit RTX GPUs providing an inexpensive means of
accelerating machine learning algorithms. The 32-bit NVIDIA RTX 3090 for
example offers 328 Tensor cores along with 10496 CUDA cores with a
maximum of 24 GB of memory. The 64-bit NVIDIA A100 offers 432 Tensor
cores along with 6912 CUDA cores for high-end computing and 40 GB or 80
GB of memory. These A100s can also be combined with the NVLink
connection so that an 8xA100 GPU cluster can look to the user like a
single GPU with 640 GB of memory.</p>
</div>
<div class="section level3">
<h3 id="profiling-gpu-code">Profiling GPU code<a class="anchor" aria-label="anchor" href="#profiling-gpu-code"></a>
</h3>
<p>It is more difficult to profile GPU programs since half of the code
is running on the CPU and half on the GPU. From outside the program, if
a user can ssh into the compute node then running
<strong>nvidia-smi</strong> provides a snapshot of the GPU utilization
and GPU memory usage. In the job script the <strong>nvprof</strong>
function can be used in place of the <strong>time</strong> function to
give profile information for various functions of the job.</p>
</div>
<div class="section level3">
<h3 id="compiling-and-running-gpu-jobs">Compiling and running GPU jobs<a class="anchor" aria-label="anchor" href="#compiling-and-running-gpu-jobs"></a>
</h3>
<p>Depending on your system you may need to load a module to gain access
to the <strong>nvcc</strong> compiler for CUDA code. <strong>nvcc
–help</strong> can provide you with all the optional parameters, but a
basic compile is like <strong>nvcc code.cu -o cuda_exec_name</strong>.
You can then run the executable like any other except that there must be
a GPU present. If you are on an HPC system with the Slurm scheduler, you
can request a single GPU by adding the <strong>–gres=gpu:1</strong>
parameter. You can also request a specific type of GPU, but this depends
on how each system is set up so you will need to refer to the user
documentations. On our HPC cluster at Kansas State University the
request for one NVIDIA RTX 3090 would be
<strong>–gres=gpu:geforce_rtx_3090:1</strong>.</p>
<div id="run-a-simple-gpu-job-if-you-have-access-to-an-hpc-system-with-gpus" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="run-a-simple-gpu-job-if-you-have-access-to-an-hpc-system-with-gpus" class="callout-inner">
<h3 class="callout-title">Run a simple GPU job if you have access to an HPC system with GPUs<a class="anchor" aria-label="anchor" href="#run-a-simple-gpu-job-if-you-have-access-to-an-hpc-system-with-gpus"></a>
</h3>
<div class="callout-content">
<p>Compile and run the hello_from_gpu.cu CUDA program. You may need to
load a module to gain access to the <strong>nvcc</strong> compiler.
There is an <strong>sb.hello_from_gpu</strong> Slurm batch script to
submit the job.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>The goal is just to start getting you comfortable with compiling and
submitting GPU jobs. Use <strong>nvcc hello_gpu.cu -o
hello_from_gpu</strong> to compile. If you have Slurm on your HPC system
you can submit the job with <strong>sbatch sb.hello_gpu</strong> but you
may need to add a partition.</p>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>GPUs are more difficult to program, so for most scientists you will
only want to know how to run codes when GPUs are involved and not how to
program them yourself. If you are fortunate enough to have an algorithm
that someone has accelerated with a GPU, GPUs can often provide an order
of magnitude increase in speed over just using CPUs and greatly reduce
the cost of doing a calculation.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Start to become comfortable with using GPUs on an HPC system.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" class="external-link">GPU
Tensor Unit explanation</a></li>
<li><a href="https://docs.nvidia.com/cuda/" class="external-link">NVIDIA CUDA programming
documentation</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units" class="external-link">NVIDIA
GPU specs</a></li>
<li><a href="https://rocm.docs.amd.com/projects/HIP/en/latest/" class="external-link">AMD Hip
programming documentation</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units" class="external-link">AMD
GPU specs</a></li>
</ul>
</div>
</section></section><section id="aio-high-throughput-computing"><p>Content from <a href="high-throughput-computing.html">High-Throughput Computing</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/high-throughput-computing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is the difference between high-throughput computing and cluster
computing?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn what types of jobs run well on HTC systems.</li>
<li>Understand how to submit jobs using OSG.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="high-throughput-computing">High-Throughput Computing<a class="anchor" aria-label="anchor" href="#high-throughput-computing"></a>
<a class="anchor" aria-label="anchor" href="#high-throughput-computing"></a>
</h2>
<hr class="half-width">
<p>A typical HPC system today is a cluster computer made of one or more
head nodes and many compute nodes tied together with a common file
server and having a batch scheduler to control where jobs run. Some of
the largest supercomputers in the world are similar conceptually to a
cluster computer but have more custom designed circuit boards as nodes
and may be packaged up and racked in a different manner than cluster
systems that use more off-the-shelf components.</p>
<p>A High-Throughput Computer (HTC) system is designed to run very large
numbers of small jobs and is often made up of many HPC systems separated
geographically. In the U.S. the main example is the Open Science Grid
(OSG) which is open for use to anyone associated with a U.S. university
or national laboratory. Time is given away freely on a first-come
first-served basis and computer resources are donated by various
institutions. Since HTC is geared toward running large numbers of
smaller jobs, the jobs fit well into the spare nooks and crannies of
most HPC systems and these systems are set up to kill any OSG job when
the host institute needs those resources back. In this way the HTC jobs
run invisibly on the over 100 HPC sites spread across the U.S. offering
free computing to any who need to run small jobs while greatly enhancing
the usage of each HPC system by using the spare CPU cycles that would
otherwise go wasted.</p>
<div class="section level3">
<h3 id="large-numbers-of-small-jobs">Large numbers of small jobs<a class="anchor" aria-label="anchor" href="#large-numbers-of-small-jobs"></a>
</h3>
<p>One of the first examples of HTC was the SETI program where
individual PC users could donate their CPU cycles to the project to
search through large quantities of data to try to find signals that
might come from intelligent life. This problem is ideal for HTC since it
can be broken up into large numbers of small jobs, and any job that did
not return an answer in a given period was just thrown away and rerun on
another system.</p>
<p>OSG has the ability to run a wide variety of jobs including large
memory and GPU runs, but it is much more difficult than running the
simple small jobs that it was designed for. The OSG guidelines for the
typical job are 1-8 cores, up to 40 GB memory and 10 GB IO, and up to 20
hours run-time.</p>
<p>The most important aspect of working with HTC systems is that the
jobs be self-contained as much as possible, and be able to run on any
operating system and use mainstream modules. This is essential since
each job may be run on a wide range of HPC environments. Executables
that are dynamically linked can work if you request the matching
resources by specifying things like acceptable CPU architectures.
Statically linked executables will always work. Containers take more
effort to set up but are ideal for HTC since all executables, modules,
and environmental variables are set within the container. Running on
multiple nodes using MPI is possible but difficult usually requiring
containers with the MPI connections specified externally.</p>
</div>
<div class="section level3">
<h3 id="using-osg">Using OSG<a class="anchor" aria-label="anchor" href="#using-osg"></a>
</h3>
<p>Users may submit jobs to the OSG queue through their institute’s
portal if one exists or through the OSG Connect submission service at
the link below. If using the OSG Connect portal you will need to request
access and arrange for a short Zoom meeting with one of their support
staff. There are links to the OSG Consortium and support documentation
at the end of this lesson.</p>
</div>
<div class="section level3">
<h3 id="working-with-the-htcondor-scheduler">Working with the HTCondor scheduler<a class="anchor" aria-label="anchor" href="#working-with-the-htcondor-scheduler"></a>
</h3>
<p>Submitting jobs to HTCondor for scheduling on any of the hundreds of
remote systems available is similar to using any scheduler, except for
the notes above on the job not relying on modules and libraries that may
not be available or labeled the same everywhere. Below is an example job
script to run the stand-alone executable <strong>namd2</strong>. Note
that the X64_64 CPU architecture is specified. The script requests 1 GB
of disk for this job and directs that all files from the directory
<strong>input_files</strong> be transferred along with the job at the
start, and all files in <strong>output</strong> be transferred back at
the end. The <strong>queue 1</strong> command then specifies the number
of these jobs to submit. If multiple jobs are submitted then the
environmental variable <strong>$(Process)</strong> will be used in the
script to differentiate each with that being between zero and the number
of jobs specified minus one.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co">#!/bin/bash -l</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a> </span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">output</span> = osg.namd.out</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="ex">error</span> = osg.namd.error</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="ex">log</span> = osg.namd.log</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a> </span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># Requested resources</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="ex">request_cpus</span> = 8</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="ex">request_memory</span> = 8 GB</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="ex">request_disk</span> = 1 GB</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="ex">requirements</span> = Arch == <span class="st">"X86_64"</span> <span class="kw">&amp;&amp;</span> <span class="ex">HAS_MODULES</span> == True</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a> </span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="ex">transfer_input_files</span> = input_files/         <span class="co"># Slash means all files in that directory</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="ex">executable</span> = namd2</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="ex">arguments</span> = +p8 test.0.namd</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="ex">transfer_output_files</span> = output</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="ex">queue</span> 1</span></code></pre>
</div>
<p>Most systems will have support for modules, but the
<strong>HAS_MODULES == True</strong> requirement can mean some systems
are not supported. Most systems use RHEL7, so specifying that may also
rule out use of RHEL6 and RHEL8 systems. In general, if you use a
mainstream operating system and modules then you should be fine.
Otherwise you likely will need to use a container.</p>
<p>Once you have the script you can submit, monitor, and control the job
using commands like those below.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="op">&gt;</span> condor_submit <span class="ex">htc_job.sh</span>                   <span class="co"># Submit the condor script to the queue</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="op">&gt;</span> condor_q                                   <span class="co"># Check on the status while in the queue</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="op">&gt;</span> condor_q <span class="ex">netid</span>                             <span class="co"># Check status of currently running jobs</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="op">&gt;</span> condor_q <span class="ex">121763</span>                            <span class="co"># Check status of a particular job</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="op">&gt;</span> condor_history <span class="ex">121763</span>                      <span class="co"># Check status of a job that is completed</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="op">&gt;</span> condor_history <span class="ex">-long</span> 121763                <span class="co"># Same but report more info</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="op">&gt;</span> condor_rm <span class="ex">121763</span>                           <span class="co"># Remove the job number specified</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="op">&gt;</span> condor_rm <span class="ex">daveturner</span>                       <span class="co"># Remove all jobs for the given username</span></span></code></pre>
</div>
</div>
</section><section><h2 class="section-heading" id="htc-outside-the-u-s-">HTC Outside the U.S.<a class="anchor" aria-label="anchor" href="#htc-outside-the-u.s."></a>
<a class="anchor" aria-label="anchor" href="#htc-outside-the-u-s-"></a>
</h2>
<hr class="half-width">
<p>Need to add info about non-US HTC systems</p>
<div id="optional-homework-get-an-osg-account-and-submit-a-test-job." class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="optional-homework-get-an-osg-account-and-submit-a-test-job." class="callout-inner">
<h3 class="callout-title">Optional Homework: Get an OSG account and submit a test job.<a class="anchor" aria-label="anchor" href="#optional-homework-get-an-osg-account-and-submit-a-test-job."></a>
</h3>
<div class="callout-content">
<p>If you are in the U.S. and want a big challenge, request an OSG
account and try submitting some small jobs.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>High-Throughput Computing is free in the U.S. using the Open Science
Grid. It is great for running large numbers of small jobs. Using it for
GPU jobs or when large memory or IO is needed is possible but much more
challenging. Aside from that it is similar to running jobs using any
other scheduler.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Explore the basics of HTC computing.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://osg-htc.org" class="external-link">OSG Consortium</a></li>
<li><a href="https://connect.osg-htc.org" class="external-link">OSG Connect</a></li>
<li><a href="https://support.opensciencegrid.org/support/home" class="external-link">OSG
support home</a></li>
<li><a href="https://osg-htc.org/services/open_science_pool.html" class="external-link">OSG
typical jobs</a></li>
<li><a href="https://support.opensciencegrid.org/support/solutions/articles/5000632058-is-the-open-science-grid-for-you-" class="external-link">OSG
typical jobs</a></li>
<li><a href="https://www.youtube.com/watch?v=oMAvxsFJaw4" class="external-link">HTCondor
scheduler youtube video</a></li>
</ul>
</div>
</section></section><section id="aio-hpc-resources"><p>Content from <a href="hpc-resources.html">HPC Resources</a></p>
<hr>
<p>Last updated on 2024-08-13 |

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/episodes/hpc-resources.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do I get access to HPC resources?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand what HPC resources are available in the U.S.</li>
<li>Learn how to access these resources for free.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="getting-access-to-hpc-resources">Getting Access to HPC Resources<a class="anchor" aria-label="anchor" href="#getting-access-to-hpc-resources"></a>
<a class="anchor" aria-label="anchor" href="#getting-access-to-hpc-resources"></a>
</h2>
<hr class="half-width">
<p>It is very typical to start a project on a personal computer only to
find that you need more performance either as computing power or memory.
The next step may be to run your code on a more powerful workstation
such as a departmental server. But when you still need more performance
where do you go? Most scientists do not understand that there are many
options for getting more powerful computing resources, and that they are
commonly free for the asking.</p>
<p>If you are in a university or laboratory environment the first place
to look is your local supercomputing center if you have one. While many
provide priority access to the compute resources to those that provide
research funds, most also have some means of providing significant
resources to users that can’t provide financial support. Many university
cluster computers work on the <strong>condo</strong> model where
scientific groups can purchase compute nodes that they have full
priority on, but in return for the university managing those compute
nodes anyone else is allowed to use them when idle. This pay for
priority model works well in sharing computing resources between the
haves and the have nots.</p>
<p>In many states one of the larger universities may provide free access
to scientists in smaller universities in the state. Kansas State
University for example provides free access to anyone associated with
any university in the state. Many other states provide funding for a
single supercomputing center that all in the state can use.</p>
<div class="section level3">
<h3 id="remote-resources">Remote resources<a class="anchor" aria-label="anchor" href="#remote-resources"></a>
</h3>
<p>There are many national supercomputing centers in the U.S. that
receive federal funding from the National Science Foundation (NSF) and
Department of Energy (DoE). These supercomputers can cost $10-$100
million or above and have capacities now over 1 exa-flops (billion
billion floating-point operations per second). When these are funded,
part of the compute cycles are designated for access to scientists not
directly associated with those institutions.</p>
<p>Account and allocation requests as well as access is handled through
user portals. Most of these remote systems have startup accounts
available that may typically be in the range of 5,000 core-hours (5000
hours on 1 core or 500 hours on 10 cores for example). Getting access is
as easy as knowing where and how to ask.</p>
<div class="section level4">
<h4 id="the-access-portal-to-remote-nsf-supercomputers">The ACCESS portal to remote NSF supercomputers<a class="anchor" aria-label="anchor" href="#the-access-portal-to-remote-nsf-supercomputers"></a>
</h4>
<p>The ACCESS portal is formerly known as XSEDE. The link below is where
to go to request an account and allocation, submit a proposal, and find
documentation and support. There are a very wide variety of
supercomputing systems available to users associated with a university
or laboratory. Small startup allocations usually only take a few minutes
to apply for and are typically approved within a few days.</p>
<p>Many universities have a <strong>Campus Champion</strong> with a
larger allocation on many systems designed to be shared across a campus.
When these allocations run out, they can simply request more but they
are intended to get users needing long-term support the experience on a
system so that they can submit a full proposal. While startup requests
are typically on a specific system and may be around 5,000 core-hours,
campus champions may be granted ~5 times as much plus access to GPU and
large memory nodes. If you are on a campus with a Campus Champion then
you just need to apply for an account then contact them to get access to
the actual allocations.</p>
<p>Follow the ACCESS link at the end of this lesson for a complete list
of supercomputing resources, but below is an example of some of the
systems available (last updated August of 2022).</p>
</div>
</div>
<div class="section level3">
<h3 id="bridges2-at-the-pittsburgh-supercomputing-center-psc">Bridges2 at the Pittsburgh Supercomputing Center (PSC)<a class="anchor" aria-label="anchor" href="#bridges2-at-the-pittsburgh-supercomputing-center-psc"></a>
</h3>
<p><strong>488 RM Regular Memory compute nodes</strong></p>
<ul>
<li>2 x AMD EPYC 7742 –&gt; 128 cores</li>
<li>256 GB memory (16 more nodes have 512 GB each)</li>
<li>3.84 TB NVMe SSD</li>
<li>Mellanox HDR 200 Gbps network</li>
</ul>
<p><strong>4 EM Extreme Memory compute nodes</strong></p>
<ul>
<li>4 x Intel Cascade 8260M –&gt; 96 cores</li>
<li>4 TB memory</li>
<li>7.68 TB NVMe SSD</li>
<li>Mellanox HDR 200 Gbps network</li>
</ul>
<p><strong>24 GPU compute nodes</strong></p>
<ul>
<li>2 x Intel Gold Cascade 6248 –&gt; 40 cores</li>
<li>8 x NVIDIA Tesla v100 32 GB sxm2 GPU cards</li>
<li>512 GB memory</li>
<li>7.68 TB NVMe SSD</li>
<li>Mellanox HDR 200 Gbps network</li>
</ul>
</div>
<div class="section level3">
<h3 id="expanse-at-the-san-diego-supercomputing-center-sdsc">Expanse at the San Diego Supercomputing Center (SDSC)<a class="anchor" aria-label="anchor" href="#expanse-at-the-san-diego-supercomputing-center-sdsc"></a>
</h3>
<p><strong>728 compute nodes</strong></p>
<ul>
<li>2 x AMD EPYC 7742 –&gt; 128 cores</li>
<li>256 GB memory</li>
</ul>
<p><strong>4 Large Memory nodes</strong></p>
<ul>
<li>4 x Intel Cascade 8260M –&gt; 96 cores</li>
<li>2 TB memory</li>
</ul>
<p><strong>52 GPU nodes</strong></p>
<ul>
<li>2 x Intel Xeon 6248 –&gt; 40 cores</li>
<li>4 x NVIDIA Tesla v100 GPU cards</li>
<li>384 GB memory</li>
</ul>
<p><strong>Cluster-wide capabilities</strong></p>
<ul>
<li>12 PetaByte Lustre file system</li>
<li>7 PetaByte CEPH object store</li>
<li>56 Gbps bi-directional HDR InfiniBand network</li>
</ul>
</div>
</section><section><h2 class="section-heading" id="national-energy-research-scientific-computing-center-nersc">National Energy Research Scientific Computing Center (NERSC)<a class="anchor" aria-label="anchor" href="#national-energy-research-scientific-computing-center-nersc"></a>
<a class="anchor" aria-label="anchor" href="#national-energy-research-scientific-computing-center-nersc"></a>
</h2>
<hr class="half-width">
<p>While allocations for the NSF supercomputing centers are managed
through the ACCESS website, external access to the Department of Energy
(DoE) supercomputers are managed through NERSC with the website link at
the end of this module. Many DoE supercomputers can be accessed by
scientists in universities and laboratories, but the process is more
involved. Access is still free, but you typically need to write a
proposal for significant node-hours and fully justify that the science
you intend to do is important and fits within the DoE mission, and
demonstrate that your code will use the requested resources
efficiently.</p>
</section><section><h2 class="section-heading" id="open-science-grid-osg">Open Science Grid (OSG)<a class="anchor" aria-label="anchor" href="#open-science-grid-osg"></a>
<a class="anchor" aria-label="anchor" href="#open-science-grid-osg"></a>
</h2>
<hr class="half-width">
<p>If you need to run many smaller jobs, then High-Throughput Computing
(HTC) covered in the previous chapter may be ideal for you. OSG access
is fairly easy for users in the U.S. and provides virtually unlimited
access.</p>
</section><section><h2 class="section-heading" id="national-research-platform-nrp">National Research Platform (NRP)<a class="anchor" aria-label="anchor" href="#national-research-platform-nrp"></a>
<a class="anchor" aria-label="anchor" href="#national-research-platform-nrp"></a>
</h2>
<hr class="half-width">
<p>The NRP is a partnership of over 50 institutions led by UC San Diego
supported in large part by NSF. The Nautilus system is a HyperCluster
for running containerized big data applications using kubernetes for the
container management. This is a distributed set of compute nodes similar
to OSG but applications must specifically be self-contained and are
guaranteed isolated access to the resources allocated.</p>
<p>While kubernetes is more difficult for the average user, this system
provides access to much more powerful computing including very high-end
GPUs. The compute nodes are mainly GPU-based and research is aimed at
Machine Learning codes.</p>
</section><section><h2 class="section-heading" id="cloud-computing">Cloud Computing<a class="anchor" aria-label="anchor" href="#cloud-computing"></a>
<a class="anchor" aria-label="anchor" href="#cloud-computing"></a>
</h2>
<hr class="half-width">
<p>Running HPC jobs in the cloud is much more difficult and costly than
many people understand. Most cloud computing vendors do give small
amounts of access away for free on a trial basis for those that want to
experiment. The amount is very minimal in the context of running an HPC
job.</p>
<p>As of August of 2024, Google Cloud Platform (GCP) offered $300 credit
to new customers for example. Amazon Web Services (AWS) offered several
free trial plans with $750 credits. Microsoft Azure offers a $200 credit
for 30 days for eligible new customers.</p>
</section><section><h2 class="section-heading" id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<hr class="half-width">
<p>Many projects that start on a laptop or desktop system end up needing
larger resources. Transitioning to an HPC system can be challenging, but
the best news is that HPC resources are often free for the asking. You
just need to know where and how to ask, and hopefully this module will
give you ideas on where to start.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>There are many HPC resources that are totally free for the
asking.</li>
</ul>
</div>
</div>
</div>
<div class="section level3">
<h3 id="links-for-additional-information">Links for additional information<a class="anchor" aria-label="anchor" href="#links-for-additional-information"></a>
</h3>
<ul>
<li><a href="https://access-ci.org" class="external-link">ACCESS Portal</a></li>
<li><a href="https://nersc.gov/" class="external-link">NERSC Portal</a></li>
<li><a href="https://osg-htc.org" class="external-link">OSG Consortium</a></li>
<li><a href="https://nationalresearchplatform.org" class="external-link">NRP National Research
Platform</a></li>
<li><a href="https://aws.amazon.com/free/" class="external-link">AWS Cloud Services</a></li>
<li><a href="https://cloud.google.com/free" class="external-link">GCP Services</a></li>
<li><a href="https://azure.microsoft.com/en-us/offers/ms-azr-0044p/" class="external-link">Microsoft
Azure</a></li>
</ul>
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/DrDaveTurner/HPC-User/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/DrDaveTurner/HPC-User/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/DrDaveTurner/HPC-User/" class="external-link">Source</a></p>
				<p><a href="https://github.com/DrDaveTurner/HPC-User/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:drdaveturner@gmail.com">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.5" class="external-link">sandpaper (0.16.5)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.6" class="external-link">pegboard (0.7.6)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.3" class="external-link">varnish (1.0.3)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://DrDaveTurner.github.io/HPC-User/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": " HPC, software, lesson, The Carpentries, Python, C, C++, Fortran, R, Matlab",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://DrDaveTurner.github.io/HPC-User/aio.html",
  "identifier": "https://DrDaveTurner.github.io/HPC-User/aio.html",
  "dateCreated": "2022-01-01",
  "dateModified": "2024-08-20",
  "datePublished": "2024-08-20"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

